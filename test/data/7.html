



kondou.com - Beautiful Soup 4.2.0 Doc. æ¥æ¬èªè¨³ (2013-11-19æçµæ´æ°)










Navigation


index
Beautiful Soup 4.2.0 Doc. æ¥æ¬èªè¨³ (2013-11-19æçµæ´æ°) »







Beautiful SoupÂ¶

Beautiful Soup ã¯HTMLãXMLãã¡ã¤ã«ãããã¼ã¿ãåå¾ããPythonã®ã©ã¤ãã©ãªã§ããããªãã®å¥½ããªãã¼ãµã¼(æ§æè§£æå¨)ãä½¿ã£ã¦ããã¼ã¹ããªã¼(æ§ææ¨)ã®æ¢ç´¢ãæ¤ç´¢ãä¿®æ­£ãè¡ãã¾ãã
ããã¯ãã­ã°ã©ãã¼ã®ä½æ¥­æéãå¤§å¹ã«ç­ç¸®ãã¦ããã¾ãã

(è¨³æ³¨)ç³é¹¸ã¯é£ã¹ãããªãÂ¶
ãã®ææ¸ã¯ Beautiful Soup 4.2.0 Documentation ã®æ¥æ¬èªè¨³ã§ãã”Beautiful Soup”ã”ãã¥ã¼ãã£ãã«ã½ã¼ã”ã¨èª­ãã§ãã¾ãè±èªãè¦æã§ã¡ãã£ã´ãHãªå¾è¼©ã®ããã«ç¿»è¨³ãã¾ããã
2013å¹´10æ29æ¥ãããã®ææ¸ã®ç¿»è¨³ãã¯ããã¾ããã11æ1æ¥ç¾å¨ã¾ã å¨ã¦ãè¨³ãçµãã¦ãã¾ããããã¹ã¯ã¬ã¤ãã³ã°ã«ä½¿ãä¸»ãªé¨åã¯ã¨ããããè¨³ããã®ã§ãä¸æ¦ããã§å¬éãã¦ããã¨ã¯å¹´åãç®å¦ã«ã¾ã£ããã¨ç¿»è¨³ããããããããã¦è³ªãé«ãã¦ãããã¨æã£ã¦ãã¾ããä»ã®ã¨ããããã¼ã¹ããªã¼ãä¿®æ­£ ä»¥éã¯ããã£ããè¨³ã®ããã«ããããªè¡¨ç¾ãå¤ããããã¨ã«ãæ³¨æãã ããã
èª¤è¨³ããããã¥ããã¨ãããè¦ã¤ãããããªã«ããæè¦ãããã¨ãã«ã¯ãè¿è¤èå¾³()ã¾ã§ãé£çµ¡ãã ããããããã£ãç¿»è¨³ãããã®ã¯ã¯ããã¦ãªã®ã§ãã¤ã£ãã¿å¤§æ­è¿ã§ãããããããé¡ããã¾ãã
2013å¹´10æç¾å¨ãBeautiful Soupã«ã¤ãã¦ã®æ¥æ¬èªWebãã¼ã¸ã¯ãBeautiful Soup 3ã¨Beautiful Soup 4ï¼ä»¥ä¸ãBS3,BS4)ã®æå ±ãæ··å¨ãã¦ãã¾ããã¨ãã«ã”Beautiful Soup”ã§æ¥æ¬èªãã¼ã¸ãå¯¾è±¡ã«ã°ã°ãã¨ãæåã«è¡¨ç¤ºããã10ä»¶ä¸­9ä»¶ãBS3ã«ããæå ±ã§ããããã«ãåå¿èã¯ãã®ã¾ã¾BS3ãä½¿ã£ã¦æ··ä¹±ããã¡ã§ãããæ³¨æãã ããã
æ··ä¹±ããªãããã«åå¿èãç¥ã£ã¦ããã¹ããã¨

2012å¹´5æã«BS3ã®éçºãçµäºããç¾å¨ã§ã¯BS4ã®å©ç¨ãæ¨å¥¨ããã¦ãã¾ã
BS3ã¯Python3ã«å¯¾å¿ãã¦ãã¾ãã
ãã ããBS3ã®ã¹ã¯ãªããã®ã»ã¨ãã©ã¯importæãå¤ããã ãã§BS4ã§ãåãã¾ã
ãã®ãããBS3ã«ããæå ±ãåé¡è§£æ±ºã®å½¹ã«ç«ã¡ã¾ã
è©³ããã¯ Beautiful Soup 3 ãèª­ãã§ãã ãã
ãã®ææ¸ã® ã¯ã¤ãã¯ã¹ã¿ã¼ã ã¨ find_all() ãèª­ãã°ããããªãã«ç¨ã¯è¶³ããã¨æãã¾ã



ãã®ææ¸ã«ã¤ãã¦Â¶
ãã®ææ¸ã¯ãBeautiful Soup 4 (è¨³æ³¨:ä»¥ä¸BS4)ã®ä¸»è¦æ©è½ã«ã¤ãã¦ãä¾ãæãã¦èª¬æãã¾ããã©ã®ã©ã¤ãã©ãªãããããã©ã®ããã«åãããã©ã®ããã«ä½¿ãããã©ã®ããã«ããªãã®æããã¨ãéæããããäºæ³å¤ã®åããããã¨ãã¯ä½ãããã°ãããã¨ãã£ããã¨ãç¤ºãã¾ãã
ãã®ææ¸ã§æããããä¾ã¯ãPython2.7ã¨3.2ã®ã©ã¡ãã§ãåãããã«åãã¾ãã
ããªãã¯ Beautiful Soup 3 (è¨³æ³¨:ä»¥ä¸BS3)ã®ææ¸ ãæ¢ãã¦ããã®ããããã¾ããããããããªããBS3ã¯ãã§ã«éçºãçµãã¦ãã¦ãBS4ãå¨ã¦ã®ãã­ã¸ã§ã¯ãå¯¾ãã¦æ¨å¥¨ããã¦ãããã¨ãç¥ã£ã¦ãã¦ãã ãããBS3ã¨BS4ã®éããç¥ãããã¨ãã¯ãBS4ã¸ã®ç§»è¡ ãè¦ã¦ãã ããã
ãã®ææ¸ã¯ãã¦ã¼ã¶ã¼ã«ããä»ã®è¨èªã«ãç¿»è¨³ããã¦ãã¾ãã

ì´ ë¬¸ìë íêµ­ì´ ë²ì­ë ê°ë¥í©ëë¤.(ì¸ë¶ ë§í¬)



å©ãã¦ã»ããã¨ãã¯Â¶
Beautiful Soup ã«ã¤ãã¦çåãçããããåé¡ã«ç´é¢ããã¨ãã¯ã ãã£ã¹ã«ãã·ã§ã³ã°ã«ã¼ãã«ã¡ã¼ã«ãã¦ãã ããã ããåé¡ãHTMLã®ãã¼ã¹ã®ãã¨ã§ããã°ããã®HTMLã«ã¤ãã¦ diagnose() é¢æ°ã®è¿ãåå®¹ ãå¿ãæ¸ãããã«ãã¦ãã ããã



ã¯ã¤ãã¯ã¹ã¿ã¼ãÂ¶
ä»¥ä¸ã®HTMLãã­ã¥ã¡ã³ãã¯ããã®ãã¨ä½åãä¾ã¨ãã¦ç¨ãããã¾ãã ãµããã®å½ã®ã¢ãªã¹ ããã®å¼ç¨ã§ãã:
html_doc = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""


ãã®”three sisters”ãã­ã¥ã¡ã³ãã Beautiful Soup ã«ãããã¨ã Beautiful Soup ãªãã¸ã§ã¯ããå¾ããã¾ããããã¯å¥ãå­ãã¼ã¿æ§é ã§ãã­ã¥ã¡ã³ããè¡¨ç¾ãã¾ãã:
from bs4 import BeautifulSoup
soup = BeautifulSoup(html_doc)

print(soup.prettify())
# <html>
#  <head>
#   <title>
#    The Dormouse's story
#   </title>
#  </head>
#  <body>
#   <p class="title">
#    <b>
#     The Dormouse's story
#    </b>
#   </p>
#   <p class="story">
#    Once upon a time there were three little sisters; and their names were
#    <a class="sister" href="http://example.com/elsie" id="link1">
#     Elsie
#    </a>
#    ,
#    <a class="sister" href="http://example.com/lacie" id="link2">
#     Lacie
#    </a>
#    and
#    <a class="sister" href="http://example.com/tillie" id="link2">
#     Tillie
#    </a>
#    ; and they lived at the bottom of a well.
#   </p>
#   <p class="story">
#    ...
#   </p>
#  </body>
# </html>


ä»¥ä¸ã¯ããã¼ã¿æ§é ãæ¢ç´¢ããããã¤ãã®æ¹æ³ã§ãã:
soup.title
# <title>The Dormouse's story</title>

soup.title.name
# u'title'

soup.title.string
# u'The Dormouse's story'

soup.title.parent.name
# u'head'

soup.p
# <p class="title"><b>The Dormouse's story</b></p>

soup.p['class']
# u'title'

soup.a
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>

soup.find_all('a')
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

soup.find(id="link3")
# <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>


ããããå¦çã¨ãã¦ããã¼ã¸ã®<a>ã¿ã°åã«ããURLãå¨ã¦æ½åºããã¨ãããã®ãããã¾ãã:
for link in soup.find_all('a'):
    print(link.get('href'))
# http://example.com/elsie
# http://example.com/lacie
# http://example.com/tillie


ã¾ãããã¼ã¸ããã¿ã°ãé¤å»ãã¦å¨ãã­ã¹ããæ½åºããã¨ããå¦çãããã¾ãã:
print(soup.get_text())
# The Dormouse's story
#
# The Dormouse's story
#
# Once upon a time there were three little sisters; and their names were
# Elsie,
# Lacie and
# Tillie;
# and they lived at the bottom of a well.
#
# ...


å¿è¦ãªæå ±ã¯å¾ããã¾ãããï¼ã¤ã¥ããã©ããã


ã¤ã³ã¹ãã¼ã«Â¶
DebianãUbuntuã®æè¿ã®ãã¼ã¸ã§ã³ãä½¿ã£ã¦ããã°ãBeautiful Soupã¯ã·ã¹ãã ã®ããã±ã¼ã¸ããã¼ã¸ã£ã§ã¤ã³ã¹ãã¼ã«ã§ãã¾ãã:
$ apt-get install python-bs4
Beautiful Soup 4 ã¯ PyPiãéãã¦å¬éããã¦ãã¾ãããã®ãããããã·ã¹ãã ããã±ã¼ã¸ã§ Beautiful Soup ãã¤ã³ã¹ãã¼ã«ã§ããªãã¨ãã¯ãeasy_install ã pip ã§ã¤ã³ã¹ãã¼ã«ã§ãã¾ãã
$ easy_install beautifulsoup4
$ pip install beautifulsoup4
( BeautifulSoup ããã±ã¼ã¸ã¯ããããããªããæ¢ãã¦ãããã®ã§ã¯ ããã¾ãã ãããã¯ãä¸ã¤åã®ã¡ã¸ã£ã¼ãªãªã¼ã¹ Beautiful Soup 3 ã§ããå¤ãã®ã½ããã¦ã§ã¢ãBS3ãä½¿ã£ã¦ãã¦ãä»ã§ãBS3ã¯å©ç¨ã§ãã¾ããããããæ°ããã³ã¼ããæ¸ãå ´åã¯ã beautifulsoup4 ãã¤ã³ã¹ãã¼ã«ãã¹ãã§ãã)
ããã easy_install ã pip ãã¤ã³ã¹ãã¼ã«ãã¦ãªãã¨ãã¯ãdownload the Beautiful Soup 4 source tarball ã§ã½ã¼ã¹ããã¦ã³ã­ã¼ãã setup.py ãç¨ãã¦ã¤ã³ã¹ãã¼ã«ã§ãã¾ãã
$ python setup.py install
ããã©ã®æ¹æ³ãå¤±æããã®ãªããããªãã®ã¢ããªã±ã¼ã·ã§ã³ã«ã©ã¤ãã©ãªããã®ã¾ã¾ããã±ã¼ã¸ã³ã°ããã¨ããæãããã¾ããBeautiful Soupã®ã©ã¤ã»ã³ã¹ã¯ãããèªãã¦ãã¾ãã.tar.gzå½¢å¼ã§ãã¦ã³ã­ã¼ãããã¢ããªã±ã¼ã·ã§ã³ã®ã½ã¼ã¹ã³ã¼ãåã« bs4 ãã£ã¬ã¯ããªãã³ãã¼ãã¦ãã ãããããããã°ãBeautiful Soupãã¤ã³ã¹ãã¼ã«ãããã¨ãªãã«ä½¿ããã¨ãã§ãã¾ãã
ç§ã¯ãPython 2.7ã¨Python 3.2ã§Beautiful Soupãéçºãã¾ããããä»ã®æè¿ã®ãã¼ã¸ã§ã³ã§ãåãã¯ãã§ãã

ã¤ã³ã¹ãã¼ã«å¾ã®åé¡Â¶
Beautiful Soupã¯Python 2ã®ã³ã¼ãã¨ãã¦ããã±ã¼ã¸ããã¦ãã¾ãã
Beautiful SoupãPython 3ç°å¢ã§ä½¿ããã¨ãã¦ã¤ã³ã¹ãã¼ã«ããã¨ãããã¯èªåçã«Python 3ã®ã³ã¼ãã¨ãã¦å¤æããã¾ãã
ãããBeautiful Soupããã±ã¼ã¸ãã¤ã³ã¹ãã¼ã«ããªãã¨ãã³ã¼ãã¯å¤æããã¾ããã
Windowsã§ã¯ãééã£ããã¼ã¸ã§ã³ãå¥ã£ã¦ããã¨ããããå ±åããã¾ãã
ImportError “No module named HTMLParser” ã¨ããã¨ã©ã¼ãè¡¨ç¤ºãããããããã¯Python 3ç°å¢ã§Python 2ã§æ¸ãããã³ã¼ããå®è¡ãããã¨ããããã§ãã
ImportError “No module named html.parser” ã¨ããã¨ã©ã¼ãè¡¨ç¤ºãããããããã¯Python 2ç°å¢ã§Python 3ã®ã§æ¸ãããã³ã¼ããå®è¡ãããã¨ããããã§ãã
ã©ã¡ãã®å ´åãã¨ãã¹ãå¯¾å¿ã¯ãBeautiful Soupã(tarballãè§£åããã¨ããã£ã¬ã¯ããªãå«ã)
å®å¨ã«ã¢ã³ã¤ã³ã¹ãã¼ã«ãã¦ãåã¤ã³ã¹ãã¼ã«ããããã¨ã§ãã
ROOT_TAG_NAME = u'[document]' è¡ã§ SyntaxError “Invalid syntax” ã®ã¨ã©ã¼ãè¡¨ç¤ºããããã
Python 2ã§æ¸ãããBeautiful Soupã®ã³ã¼ããPython 3ã«å¤æããªããã°ããã¾ããã
ãã®ããã«ã¯ãæ¬¡ã®ããã«ããã±ã¼ã¸ãã¤ã³ã¹ãã¼ã«ãããã:
$ python3 setup.py install
ãããã¯ãæåã§ 2to3 å¤æã¹ã¯ãªããã bs4 ãã£ã¬ã¯ããªã§å®è¡ããã°ã§ãã¾ãã:
$ 2to3-3.2 -w bs4


ãã¼ãµã¼ã®ã¤ã³ã¹ãã¼ã«Â¶
Beautiful Soupã¯Pythonã®æ¨æºã©ã¤ãã©ãªã«å¥ã£ã¦ããHTMLãã¼ãµã¼ããµãã¼ãããã¨åæã«ãå¤ãã®ãµã¼ããã¼ãã£ã¼ã®Pythonãã¼ãµã¼ããµãã¼ããã¦ãã¾ããä¸ã¤ã«ã¯ã lxml parser. ãããã¾ããç°å¢ã«ä¾ãã¾ãããä»¥ä¸ã®ã³ãã³ãã®ã©ããã§lxmlãã¤ã³ã¹ãã¼ã«ã§ããã§ãããã:
$ apt-get install python-lxml
$ easy_install lxml
$ pip install lxml
å¥ã®é¸æè¢ã¨ãã¦ãPythonç´æ­£ã® html5lib parser ãæãããã¾ããããã¯ HTMLãwebãã©ã¦ã¶ãããããã«ãã¼ã¹ãã¾ãããããç°å¢ã«ä¾ãã¾ãããä»¥ä¸ã®ã³ãã³ãã®ã©ããã§html5libãã¤ã³ã¹ãã¼ã«ã§ããã§ãããã:
$ apt-get install python-html5lib
$ easy_install html5lib
$ pip install html5lib
ä»¥ä¸ã®è¡¨ã¯ãåãã¼ãµã¼ã®ã©ã¤ãã©ãªã®å¼·ã¿ã¨å¼±ã¿ãã¾ã¨ãã¦ããã¾ãã








ãã¼ãµã¼
ä½¿ç¨ä¾
å¼·ã¿
å¼±ã¿

Python’s html.parser
BeautifulSoup(markup, "html.parser")

æ¨æºã©ã¤ãã©ãª
ã¾ãã¾ãã®ã¹ãã¼ã
Python2.7.3/3.2.2ä»¥éã«å¯¾å¿



Python2.7.3/3.2.2æªæºã¯éå¯¾å¿



lxml’s HTML parser
BeautifulSoup(markup, "lxml")

çé
å¯¾å¿(?)



å¤é¨Cã©ã¤ãã©ãªã«ä¾å­



lxml’s XML parser
BeautifulSoup(markup, ["lxml", "xml"])
BeautifulSoup(markup, "xml")

çé
å¯ä¸ã®å¯¾å¿XMLãã¼ãµã¼



å¤é¨Cã©ã¤ãã©ãªã«ä¾å­



html5lib
BeautifulSoup(markup, "html5lib")

å¯¾å¿åº¦é«
WEBãã©ã¦ã¶ã¨åãããã«ãã¼ã¹
æ­£ããHTML5ãçæ



ã¨ã¦ãéã
å¤é¨Pythonã©ã¤ãã©ãªã«ä¾å­





ã§ããã°ãéåº¦ã®ããã«lxmlãã¤ã³ã¹ãã¼ã«ãã¦ä½¿ããã¨ããè¦ããã¾ãã
ã¨ãã«ãããªããPython2.7.3ã®Python2ç³»ããPython3.2.2ããåã®Python3ç³»ãä½¿ã£ã¦ããã°ããã¯ãlxmlãhtml5libãã¤ã³ã¹ãã¼ã«ãããã¨ã¯ ã¨ã¦ãå¤§äºã§ã ã
ãªããªããPythonã«ã¯ããããçµã¿è¾¼ã¾ãã¦ããHTMLãã¼ãµã¼ã¯ãå¤ããã¼ã¸ã§ã³ã®Pythonã§ã¯ããã¾ã§è¯ãåããªãããã§ãã
æ§æãä¸æ­£ç¢ºãªãã­ã¥ã¡ã³ãã®ã¨ãã¯ããã¼ãµã¼ãéãã¨çæããããã¼ã¹ããªã¼ãç°ãªã£ã¦ãããã¨ã«æ³¨æãã¦ãã ããã
è©³ããã¯ã ãã¼ãµã¼ã®éã ãåç§ã®ãã¨ã



ã¹ã¼ãã®ä½æÂ¶
ãã­ã¥ã¡ã³ãããã¼ã¹(æ§æè§£æ)ããã«ã¯ã
ãã®ãã­ã¥ã¡ã³ãã Beautiful Soup ã³ã³ã¹ãã©ã¯ã¿ã«æ¸¡ãã¾ãã
æå­åã§ãéãããã¡ã¤ã«ãã³ãã«ã§ãæ¸¡ãã¾ãã:
from bs4 import BeautifulSoup

soup = BeautifulSoup(open("index.html"))

soup = BeautifulSoup("<html>data</html>")


æåã«ããã­ã¥ã¡ã³ãã¯Unicodeã«å¤æãããHTMLã¨ã³ãã£ãã£ã¯Unicodeæå­åã«å¤æããã¾ãã:
BeautifulSoup("Sacr&eacute; bleu!")
<html><head></head><body>SacrÃ© bleu!</body></html>

Beautiful Soupã¯ããã­ã¥ã¡ã³ãããã£ã¨ãé©ãããã¼ãµã¼(æ§æè§£æå¨)ãä½¿ã£ã¦ãã¼ã¹ãã¾ãã
XMLãã¼ãµã¼ãä½¿ãããã«æå®ããªããã°ãHTMLãã¼ãµã¼ãç¨ãããã¾ãã( XMLã®ãã¼ã¹ ãåç§)


4ç¨®é¡ã®ãªãã¸ã§ã¯ãÂ¶
Beautiful Soup ã¯è¤éãªHTMLãã­ã¥ã¡ã³ãããPythonãªãã¸ã§ã¯ãã®è¤éãªããªã¼æ§é ã«å¤æãã¾ãã
ããããããªãã¯ Tag, NavigableString, BeautifulSoup, Comment
ã® 4ç¨®é¡ã®ãªãã¸ã§ã¯ã ã ããæ±ãã°ããã§ãã

Tag obj.Â¶
Tag ãªãã¸ã§ã¯ãã¯ãåã®ãã­ã¥ã¡ã³ãåã®XMLãHTMLã®ã¿ã°ã«å¯¾å¿ãã¦ãã¾ãã:
soup = BeautifulSoup('<b class="boldest">Extremely bold</b>')
tag = soup.b
type(tag)
# <class 'bs4.element.Tag'>


Tag ãªãã¸ã§ã¯ãã¯ãå¤ãã®å±æ§ã¨ã¡ã½ãããæã£ã¦ãã¾ãããããã®ã»ã¨ãã©ã¯ã ãã¼ã¹ããªã¼ãæ¢ç´¢ ã¨ ãã¼ã¹ããªã¼ãæ¤ç´¢ ã§èª¬æãã¾ãããã®ç¯ã§ã¯ Tag ãªãã¸ã§ã¯ãã®éè¦ãªæ©è½ã§ãããååã¨å±æ§ã«ã¤ãã¦èª¬æãã¾ãã

ååÂ¶
ã¿ã°ã¯ããããååãæã£ã¦ãã¾ããã .name ã§ã¢ã¯ã»ã¹ã§ãã¾ãã:
tag.name
# u'b'


ã¿ã°ã®ååãå¤ããã¨ããã®å¤æ´ã¯Beautiful Soupãçæããå¨ã¦ã®ãã¼ã¯ã¢ããã«åæ ããã¾ãã:
tag.name = "blockquote"
tag
# <blockquote class="boldest">Extremely bold</blockquote>




å±æ§Â¶
ã¿ã°ã¯å¤ãã®å±æ§ãæã¡ã¾ãã
<b class=”boldest”>ã¯ã”boldest”ã¨ããå¤ã®’class’å±æ§ãæã¡ã¾ãã
Tag ãªãã¸ã§ã¯ããè¾æ¸ã®ããã«æ±ããã¨ã§ããã®ã¿ã°ã®å±æ§ã«ã¢ã¯ã»ã¹ã§ãã¾ãã:
tag['class']
# u'boldest'


.attrs ã§è¾æ¸ã«ç´æ¥ã¢ã¯ã»ã¹ã§ãã¾ãã:
tag.attrs
# {u'class': u'boldest'}


ç¹°ãè¿ãã«ãªãã¾ãããè¾æ¸ã®ããã« Tag ãªãã¸ã§ã¯ããæ±ããã¨ã«ãããã¿ã°ã®å±æ§ã«å¯¾ãã¦è¿½å , åé¤, ä¿®æ­£ãè¡ããã¨ãã§ãã¾ãã:
tag['class'] = 'verybold'
tag['id'] = 1
tag
# <blockquote class="verybold" id="1">Extremely bold</blockquote>

del tag['class']
del tag['id']
tag
# <blockquote>Extremely bold</blockquote>

tag['class']
# KeyError: 'class'
print(tag.get('class'))
# None



å¤ãè¤æ°ã®ã¨ãÂ¶
HTML4ã¯ãå¤ãè¤æ°ãã¦ã2,3ã®å±æ§ãå®ç¾©ãã¦ãã¾ãã
HTML5ã§ããããã¯ãªããªãã¾ããããå¥ã®åæ§ã®å±æ§ãå®ç¾©ããã¾ããã
ãã£ã¨ãä¸è¬çãªå¤ãè¤æ°ãã¤å±æ§ã¯ class ã§ãã(ãã¨ãã°ãHTMLã¿ã°ã¯è¤æ°ã®CSSã¯ã©ã¹ãæã¤ãã¨ãã§ãã¾ã)
ã¾ãä»ã®è¤æ°ã®å¤ãæã¤å±æ§ã¨ãã¦ã¯ã rel, rev, accept-charset, headers, accesskey ãããã¾ãã
Beautiful Soupã¯ããããã®å±æ§ããã¤è¤æ°ã®å¤ããªã¹ãã¨ãã¦ç¤ºãã¾ãã:
css_soup = BeautifulSoup('<p class="body strikeout"></p>')
css_soup.p['class']
# ["body", "strikeout"]

css_soup = BeautifulSoup('<p class="body"></p>')
css_soup.p['class']
# ["body"]


ããå±æ§ãè¤æ°ã®å¤ããã£ã¦ããããã§ããHTMLæ¨æºã®å®ç¾©ããå¤ãã¦ããå ´åãBeautiful Soupã¯ãã®å±æ§ãã²ã¨ã¾ã¨ã¾ãã®å¤ã¨ãã¦æ±ãã¾ãã:
id_soup = BeautifulSoup('<p id="my id"></p>')
id_soup.p['id']
# 'my id'


ã¿ã°ãæå­åã«å¤æããã¨ãã¯ããããã®å±æ§ã®è¤æ°ã®å¤ã¯ä¸ã¤ã«ã¾ã¨ãããã¾ãã:
rel_soup = BeautifulSoup('<p>Back to the <a rel="index">homepage</a></p>')
rel_soup.a['rel']
# ['index']
rel_soup.a['rel'] = ['index', 'contents']
print(rel_soup.p)
# <p>Back to the <a rel="index contents">homepage</a></p>


ãã­ã¥ã¡ã³ããXMLã¨ãã¦ãã¼ã¹ããã¨ãå¤ãè¤æ°ãã¤å±æ§ã¯ãªããªãã¾ãã:
xml_soup = BeautifulSoup('<p class="body strikeout"></p>', 'xml')
xml_soup.p['class']
# u'body strikeout'






NavigableString obj.Â¶
ã¿ã°ã®çµã«æã¾ããç­ã(ãã­ã¥ã¡ã³ãã®æ¬æã®ãã­ã¹ã)æå­åãããã¾ãã
Beautiful Soupã¯ããããã®æå­åãè¡¨ãã®ã« NavigableString ã¯ã©ã¹ãç¨ãã¾ãã:
tag.string
# u'Extremely bold'
type(tag.string)
# <class 'bs4.element.NavigableString'>


NavigableString ãªãã¸ã§ã¯ãã¯ãPythonã®Unicodeåã®ããã«æ¯ãã¾ãã¾ãã
ã¾ãããã¼ã¹ããªã¼ãæ¢ç´¢ ã¨ ãã¼ã¹ããªã¼ãæ¤ç´¢ ã«è¿°ã¹ããã¦ããæ©è½ã®ããã¤ãããµãã¼ããã¾ãã
unicode() ãç¨ãã¦ã NavigableString ãªãã¸ã§ã¯ããUnicodeåã«å¤æã§ãã¾ãã:
unicode_string = unicode(tag.string)
unicode_string
# u'Extremely bold'
type(unicode_string)
# <type 'unicode'>


NavigableString ã®æå­åã¯ç·¨éã§ãã¾ãããã replace_with() ãä½¿ã£ã¦ãä»ã®æå­åã«ç½®æãããã¨ã¯ã§ãã¾ãã:
tag.string.replace_with("No longer bold")
tag
# <blockquote>No longer bold</blockquote>


NavigableString ã¯ããã¼ã¹ããªã¼ãæ¢ç´¢ ã¨ ãã¼ã¹ããªã¼ãæ¤ç´¢ ã§è¿°ã¹ããã¦ããæ©è½ã®ã»ã¨ãã©ããµãã¼ããã¾ãã
ããããå¨ã¦ããµãã¼ããã¦ããããã§ã¯ããã¾ããã
ã¨ãã«ãTag ãªãã¸ã§ã¯ããæå­åãå¥ã® Tag ãåã«å«ãã®ã«å¯¾ãã¦ãstring ãªãã¸ã§ã¯ãã¯ä½ãæããã.contents` å±æ§, .string å±æ§, find() ã¡ã½ããããµãã¼ããã¾ããã
NavigableString ãBeautiful Soupã®å¤ã§ä½¿ãããå ´åã¯ã unicode() ãä½¿ã£ã¦Pythonã®Unicodeæå­åã«å¤æããã¹ãã§ããããããªãã¨ãBeautiful Soupãä½¿ãçµãã£ãå¾ããBeautiful Soupã®ãã¼ã¹ããªã¼å¨ä½ã¸ã®ãªãã¡ã¬ã³ã¹ãæã¡ç¶ãããã¨ã«ãªããã¡ã¢ãªãå¤§éã«æµªè²»ãã¾ãã


BeautifulSoup obj.Â¶
Beautiful Soup ãªãã¸ã§ã¯ãã¯ãããèªèº«ã§åã®ãã­ã¥ã¡ã³ãå¨ä½ãè¡¨ãã¦ãã¾ãã
ããã¦ãã®å ´åãTag obj. ãæ±ããã¨ã§ãç¨ã¯è¶³ããã§ãããã
ããã¯ãTag obj. ã ãã¼ã¹ããªã¼ãæ¢ç´¢ ã¨ ãã¼ã¹ããªã¼ãæ¤ç´¢. ã§è¿°ã¹ããã¦ããã¡ã½ããã®å¤ãããµãã¼ããã¦ããã¨ãããã¨ã§ãã
BeautifulSoup ãªãã¸ã§ã¯ãã¯ãå®éã®HTMLãXMLã¿ã°ã«å¯¾å¿ãã¦ããªãã®ã§ãååãå±æ§ãæããªãã
ãããã .name ãã¿ããããªä¾¿å©ãªãã®ã¯ããã¤ããããããã¦ããããã¯ç¹å¥ãª .name “[document]”ãå¾ããã(?è¨³ãããããããã©æ¬¡åã¾ãã?):
soup.name
# u'[document]'




Comments obj. ä»Â¶
Tag, NavigableString, BeautifulSoup ã¯HTMLãXMLãã¡ã¤ã«ã®ã»ã¼å¨ã¦ãã«ãã¼ãã¾ããããããå°ãã ãæ®ã£ããã®ãããã¾ããããã¯ã³ã¡ã³ãã«ã¤ãã¦ã§ãã:
markup = "<b><!--Hey, buddy. Want to buy a used parser?--></b>"
soup = BeautifulSoup(markup)
comment = soup.b.string
type(comment)
# <class 'bs4.element.Comment'>


Comment ãªãã¸ã§ã¯ãã¯ã NavigableString ãªãã¸ã§ã¯ãã®ç¹å¥ãªã¿ã¤ãã§ãã:
comment
# u'Hey, buddy. Want to buy a used parser'


ã³ã¡ã³ãã¯HTMLã®ä¸­ã«ããããã¾ããã Comment ã¯ç¹å¥ãªæ¸å¼ã§è¡¨ç¤ºããã¾ãã:
print(soup.b.prettify())
# <b>
#  <!--Hey, buddy. Want to buy a used parser?-->
# </b>


Beautiful Soupã¯ãXMLãã­ã¥ã¡ã³ãã®ãªãã®ä»ã®å¨ã¦ã®è¦ç´ ãã¯ã©ã¹å®ç¾©ãã¦ãã¾ãã
CData, ProcessingInstruction, Declaration, Doctype.
Comment ã¯ã©ã¹ã®ããã«ããããã¯æå­ã«ä½ããå ãã NavigableString ã®ãµãã¯ã©ã¹ã§ãã
ããã§ã¯ãã³ã¡ã³ããCDDATAãã­ãã¯ã«ç½®æããä¾ãç¤ºãã¾ãã:
from bs4 import CData
cdata = CData("A CDATA block")
comment.replace_with(cdata)

print(soup.b.prettify())
# <b>
#  <![CDATA[A CDATA block]]>
# </b>





ãã¼ã¹ããªã¼ãæ¢ç´¢Â¶
ããã§åã³ “Three sisters” ã®HTMLãã­ã¥ã¡ã³ãã§ãã:
html_doc = """
<html><head><title>The Dormouse's story</title></head>

<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""

from bs4 import BeautifulSoup
soup = BeautifulSoup(html_doc)


ãã­ã¥ã¡ã³ãã®ããé¨åããä»ã®é¨åã¸ã©ã®ããã«ç§»åããããç¤ºãããã«ããã®ãã­ã¥ã¡ã³ããä¾ã«ä½¿ã£ã¦ããã¾ãã

å­è¦ç´ ã¸ä¸ç§»åÂ¶
ã¿ã°ã¯ãã®éã«(ãã­ã¥ã¡ã³ãæ¬æã®ãã­ã¹ã)æå­åãä»ã®ã¿ã°ãæãã§ãã¾ãããããã®è¦ç´ ã¯ã ã¿ã°ã® å­è¦ç´  ã§ããBeautiful Soupã¯ãã¿ã°ã®å­è¦ç´ ãæ¢ç´¢ãæ±ãããã®å¤ãã®å±æ§ãæä¾ãã¾ãã
Beautiful Soupã®æå­åã¯ããããã®å±æ§ããµãã¼ããã¾ããããªããªããæå­åã¯å­è¦ç´ ããããªãããã§ãã

ã¿ã°åã§æ¢ç´¢Â¶
ãã¼ã¹ããªã¼ãæ¢ç´¢ããä¸çªç°¡åãªæ¹æ³ã¯ãããªããåå¾ãããã¿ã°ã®ååãä½¿ããã¨ã§ãã
ããã<head> ã¿ã°ãåå¾ããããã°ã soup.head ã¨å¥åããã°ããã§ãã:
soup.head
# <head><title>The Dormouse's story</title></head>

soup.title
# <title>The Dormouse's story</title>


ã¾ãããã¼ã¹ããªã¼ã®ããé¨åããåºçºãã¦ãä½åº¦ããºã¼ã ã¤ã³ãç¹°ãè¿ãæ¹æ³ãããã¾ãã
ãã®ã³ã¼ãã¯ã<body>ã¿ã°ä»¥ä¸ã®æåã®<b>ã¿ã°ãåå¾ãã¾ãã:
soup.body.b
# <b>The Dormouse's story</b>


å±æ§ã¨ãã¦ã¿ã°åãä½¿ãã¨ããã®ååã®ã¿ã°ã®ãã¡ æå ã«ãããã®ãåå¾ã§ãã¾ãã:
soup.a
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>


å¨ã¦ã® <a>ã¿ã°ãåå¾ãããã¨ãããããååã®ã¿ã°ã®ãã¡2çªç®ä»¥éã®ãã®ããããã¨ãã¯ã  ãã¼ã¹ããªã¼ãæ¤ç´¢ ã§è¿°ã¹ããã¦ãã find_all() ã®ãããªã¡ã½ãããä½¿ãå¿è¦ãããã¾ãã:
soup.find_all('a')
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]




.contents / .childrenÂ¶
ã¿ã°ã®å­è¦ç´ ã¯ã .contents ã§å¼ã³åºãã¨ããªã¹ãã§åå¾ã§ãã¾ãã:
head_tag = soup.head
head_tag
# <head><title>The Dormouse's story</title></head>

head_tag.contents
[<title>The Dormouse's story</title>]

title_tag = head_tag.contents[0]
title_tag
# <title>The Dormouse's story</title>
title_tag.contents
# [u'The Dormouse's story']

Beautiful Soup ãªãã¸ã§ã¯ãã¯ãããèªèº«ãå­è¦ç´ ãæã¡ã¾ãããã®å ´åã<html>ã¿ã°ã Beautiful Soup ãªãã¸ã§ã¯ãã®å­è¦ç´ ã«ãªãã¾ãã:
len(soup.contents)
# 1
soup.contents[0].name
# u'html'


æå­åã¯ .contents ãæã¡ã¾ããããªããªããæå­åã¯ä½ãæã¾ãªãããã§ãã:
text = title_tag.contents[0]
text.contents
# AttributeError: 'NavigableString' object has no attribute 'contents'


ã¿ã°ã®å­è¦ç´ ãããªã¹ãã®ä»£ããã«ã .children ã¸ã§ãã¬ã¼ã¿ã¼ãç¨ãã¦ã¤ãã¬ã¼ã¿ã¼ã§æ±ããã¨ãã§ãã¾ãã:
for child in title_tag.children:
    print(child)
# The Dormouse's story




.descendantsÂ¶
.contents ã¨ .children å±æ§ã¯ãããã¿ã°ã® ç´ä¸ã® å­è¦ç´ ã®ã¿ãè¡¨ãã¾ãã
ä¾ãã°ã<head>ã¿ã°ã¯ããã ä¸ã¤ã®ç´ä¸ã®å­è¦ç´ ã§ãã<title>ã¿ã°ãæã¡ã¾ãã:
head_tag.contents
# [<title>The Dormouse's story</title>]


ãããããã®<title>ã¿ã°èªèº«ããå­è¦ç´ ã«”The Dormouse’s story”æå­åãæã¡ã¾ãã
ãã®æå­åãã¾ãã<head>ã¿ã°ã®å­è¦ç´ ã§ããã¨ããæå³ã«ãªãã¾ãã
ããã§ã .descendants (å­å­«) å±æ§ãç¨ããã¨ã ããã¿ã°ã® å¨ã¦ã® å­è¦ç´ ãåå¸°çã«åãåºããã¨ãã§ãã¾ãã
åå¸°çã¨ããã®ã¯ãç´ä¸ã®å­è¦ç´ ããã®ã¾ãå­è¦ç´ ãããã¦ããã«ã¨ãã£ããµãã«ç¹°ãè¿ãã¦ã¨ãããã¨ã§ãã
for child in head_tag.descendants:
    print(child)
# <title>The Dormouse's story</title>
# The Dormouse's story


ãã®ãã­ã¥ã¡ã³ãã®<head>ã¿ã°ã¯ãã 1ã¤ã®å­è¦ç´ ããæã¡ã¾ãããã
<title>ã¿ã°ã¨<title>ã¿ã°ã®å­è¦ç´ ã¨ãã2ã¤ã®å­å­«è¦ç´ ãæã¡ã¾ãã
ã¾ãããã®ãã­ã¥ã¡ã³ãã® BeautifulSoup ãªãã¸ã§ã¯ãã«ã¯ã
ç´ä¸ã®å­è¦ç´ ã¯<html>ã¿ã°1ã¤ããããã¾ããããå­å­«è¦ç´ ã¯ããããããã¾ãã:
len(list(soup.children))
# 1
len(list(soup.descendants))
# 25




.stringÂ¶
ãã Tag ãªãã¸ã§ã¯ãã1ã¤ã ãå­è¦ç´ ããã£ã¦ãã¦ããã®å­è¦ç´ ã NavigableString ãªãã¸ã§ã¯ããªãã°ã .string å±æ§ã§å©ç¨ã§ãã¾ãã:
title_tag.string
# u'The Dormouse's story'


ãã Tag ãªãã¸ã§ã¯ãã®ãã 1ã¤ã®å­è¦ç´ ããå¥ã® Tag ãªãã¸ã§ã¯ãã§ãã£ã¦ .string å±æ§ãæã¤ãªãã°ãåã® Tag ãªãã¸ã§ã¯ããåã .string å±æ§ãæã¤ã¨èãããã¾ãã:
head_tag.contents
# [<title>The Dormouse's story</title>]

head_tag.string
# u'The Dormouse's story'


ãã tag ãªãã¸ã§ã¯ããè¤æ°ã®å­è¦ç´ ãæã¡ã .string å±æ§ãã©ã®å­è¦ç´ ãåç§ãã¦ãããããããªãã¨ãã .string å±æ§ã¯ None ã¨å®ç¾©ããã¾ãã:
print(soup.html.string)
# None




.strings / .stripped_stringsÂ¶
ããã¿ã°ã®ä¸­ã«ãããã­ã¥ã¡ã³ãæ¬æãè¦ç´ ãè¤æ°ã§ãã£ã¦ãããããã®æå­åãã¿ããã¨ãã§ãã¾ãã
ãã®å ´åã¯ã .strings ã¸ã§ãã¬ã¼ã¿ã¼ãä½¿ç¨ãã¾ãã:
for string in soup.strings:
    print(repr(string))
# u"The Dormouse's story"
# u'\n\n'
# u"The Dormouse's story"
# u'\n\n'
# u'Once upon a time there were three little sisters; and their names were\n'
# u'Elsie'
# u',\n'
# u'Lacie'
# u' and\n'
# u'Tillie'
# u';\nand they lived at the bottom of a well.'
# u'\n\n'
# u'...'
# u'\n'


ãããã®æå­åã¯ãå¤§éã®ä½è¨ãªç©ºç½ãå¥ããã¡ã§ããã
ããã§ã .stripped_strings ã¸ã§ãã¬ã¼ã¿ã¼ãä»£ããã«ç¨ãããã¨ã§ããããç©ºç½ãé¤ããã¨ãã§ããã:
for string in soup.stripped_strings:
    print(repr(string))
# u"The Dormouse's story"
# u"The Dormouse's story"
# u'Once upon a time there were three little sisters; and their names were'
# u'Elsie'
# u','
# u'Lacie'
# u'and'
# u'Tillie'
# u';\nand they lived at the bottom of a well.'
# u'...'


ããã§ã¯ãæå­åä¸­ã«å¥ãç©ºç½ã¯ãã®ã¾ã¾ã§ãæå­åã®æåãæå¾ã«ä»ãç©ºç½ã¯åé¤ããã¾ãã



è¦ªè¦ç´ ã¸ä¸ç§»åÂ¶
“å®¶æããªã¼”ã«ä¾ããã¨ãå¨ã¦ã®ã¿ã°ãæå­åã¯ãããããä¸ã¤ã®è¦ªè¦ç´ ãæã¡ã¾ãã

.parentÂ¶
.parent å±æ§ã§è¦ªè¦ç´ ã«ã¢ã¯ã»ã¹ã§ãã¾ãã
ãã¨ãã°ã”three sisters”ãã­ã¥ã¡ã³ãã§ã¯ã<head>ã¿ã°ã¯<title>ã¿ã°ã®è¦ªè¦ç´ ã§ãã:
title_tag = soup.title
title_tag
# <title>The Dormouse's story</title>
title_tag.parent
# <head><title>The Dormouse's story</title></head>


ã¿ã¤ãã«æå­åã¯ããèªèº«ãè¦ªè¦ç´ ãæã¡ã<title>ã¿ã°ã¯ã¿ã¤ãã«æå­åãå­è¦ç´ ã«æã¡ã¾ãã:
title_tag.string.parent
# <title>The Dormouse's story</title>


<html>ã¿ã°ã®æ§ãªãããã¬ãã«ã®ã¿ã°ã¯ã BeautifulSoup ãªãã¸ã§ã¯ãããèªèº«ã«ãªãã¾ãã:
html_tag = soup.html
type(html_tag.parent)
# <class 'bs4.BeautifulSoup'>


ããã¦ãBeautifulSoup ãªãã¸ã§ã¯ãã® .parent å±æ§ã¯ãNoneã«ãªãã¾ãã:
print(soup.parent)
# None




.parentsÂ¶
ããã¿ã°ã«å¯¾ããç¥åè¦ç´ å¨ã¦ã .parents ã§åå¾ãããã¨ãã§ãã¾ãã
ä»¥ä¸ã¯ãHTMLãã­ã¥ã¡ã³ãã®æ·±ãã¨ããã«ãã<a>ã¿ã°ããã¹ã¿ã¼ããã¦ãæä¸å±¤ã¾ã§è¾¿ã£ã¦ãã¾ãã:
link = soup.a
link
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
for parent in link.parents:
    if parent is None:
        print(parent)
    else:
        print(parent.name)
# p
# body
# html
# [document]
# None





åå¼è¦ç´ ã¸æ¨ªç§»åÂ¶
ä»¥ä¸ã®ãããªã·ã³ãã«ãªHTMLãã­ã¥ã¡ã³ããèãã¦ã¿ã¾ãããã:
sibling_soup = BeautifulSoup("<a><b>text1</b><c>text2</c></b></a>")
print(sibling_soup.prettify())
# <html>
#  <body>
#   <a>
#    <b>
#     text1
#    </b>
#    <c>
#     text2
#    </c>
#   </a>
#  </body>
# </html>


<b>ã¿ã°ã¯<c>ã¿ã°ã¨åãã¬ãã«ã«ããã¾ããã¤ã¾ãã2ã¤ã¯ã¨ãã«åãã¿ã°ã®ç´ä¸ã®å­è¦ç´ ã¨ãããã¨ã§ãã
ãããã£ãé¢ä¿ã«ããã¿ã°ã siblings (åå¼)ã¨ããã¾ãã
HTMLãã­ã¥ã¡ã³ãããããã«åºå(?)ããã¨ããsiblingsã¯åãã¤ã³ãã³ãã¬ãã«ã«ãªãã¾ãã
ãããã£ãã¿ã°ã®é¢ä¿ãã³ã¼ãã§å©ç¨ãããã¨ãã§ãã¾ãã

.next_sibling / .previous_siblingÂ¶
.next_sibling ã¨ .previous_sibling ãç¨ãã¦ããã¼ã¹ããªã¼ã®åãã¬ãã«ã®è¦ç´ éãè¾¿ããã¨ãã§ãã¾ãã:
sibling_soup.b.next_sibling
# <c>text2</c>

sibling_soup.c.previous_sibling
# <b>text1</b>


ãã®<b>ã¿ã°ã¯ .next_sibling ã¯æã¡ã¾ããã .previous_sibling ã¯æã¡ã¾ããã
ãªããªãã<b>ã¿ã°ã®åã«ã¯ãã¼ã¹ããªã¼ã§åã¬ãã«ã®è¦ç´ ããªãããã§ãã
åæ§ã«ã<c>ã¿ã°ã¯ .previous_sibling ãæã¡ã¾ããã.next_sibling ã¯æã¡ã¾ããã:
print(sibling_soup.b.previous_sibling)
# None
print(sibling_soup.c.next_sibling)
# None


“text1”ã¨”text”ã¯åå¼ã§ã¯ããã¾ããããªããªãã2ã¤ã¯åãè¦ªããããªãããã§ãã:
sibling_soup.b.string
# u'text1'

print(sibling_soup.b.string.next_sibling)
# None


å®éã®HTMLãã­ã¥ã¡ã³ãããã¼ã¹ããã¨ã .next_sibling ã .previous_sibling ã¯åå¾ã«ç©ºç½ãæã¡ã¾ãã
“three sisters”ãã­ã¥ã¡ã³ãã§è¦ã¦ã¿ã¾ãããã:
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a>
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>

ããªãã«èããã°ãæåã®<a>ã¿ã°ã® .next_sibling ã¯2çªç®ã®<a>ã¿ã°ã¨ãªãã¯ãã§ãããå®éã¯éãã¾ãã
ããã¯ãæåã®<a>ã¿ã°ã¨2çªç®ãåãã”ã³ã³ãã¨æ¹è¡ã³ã¼ã”ã¨ããæå­åã«ãªãã¾ãã:
link = soup.a
link
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>

link.next_sibling
# u',\n'


2çªç®ã®<a>ã¿ã°ã¯ããã®ã³ã³ãã¨æ¹è¡ã³ã¼ãã® .next_sibling ã«ãªãã¾ãã:
link.next_sibling.next_sibling
# <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>




.next_siblings / .previous_siblingsÂ¶
è¤æ°ã®åå¼è¦ç´ ã .next_siblings ã .previous_siblings ãã¤ãã¬ã¼ã¿ã¼ã¨ãã¦ä½¿ã£ã¦ãã¾ã¨ãã¦æ±ãã¾ãã:
for sibling in soup.a.next_siblings:
    print(repr(sibling))
# u',\n'
# <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>
# u' and\n'
# <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>
# u'; and they lived at the bottom of a well.'
# None

for sibling in soup.find(id="link3").previous_siblings:
    print(repr(sibling))
# ' and\n'
# <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>
# u',\n'
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
# u'Once upon a time there were three little sisters; and their names were\n'
# None





åå¾ã®è¦ç´ ã¸ç§»åÂ¶
“three sisters”ãã­ã¥ã¡ã³ãã®ã¯ããã®é¨åãè¦ã¦ã¿ã¾ãããã:
<html><head><title>The Dormouse's story</title></head>
<p class="title"><b>The Dormouse's story</b></p>

HTMLãã¼ãµã¼ã¯ããã®æå­åãèª­ã¿è¾¼ã¿ãã¤ãã³ãã®é£ãªãã¨ãã¦çè§£ãã¾ãã”open an <html> tag”, “open a <head> tag”, “open a <title> tag”, “add a string”, “close the <title> tag”, “open a <p>”... ã¨ãã£ããããã§ããBeautiful Soupã¯ãã®ã¤ãã³ãã®é£ãªãããããã«åæ§æãã¦æ±ãã¾ãã

.next_element / .previous_elementÂ¶
æå­åãHTMLã¿ã°ã® .next_element å±æ§ã¯ãããã®ç´å¾ã®è¦ç´ ãæãç¤ºãã¾ãã
.next_string ã¨åãããã§ãããæ±ºå®çã«éãã¾ãã
“three sisters”ãã­ã¥ã¡ã³ãã®æå¾ã®<a>ã¿ã°ã«ã¤ãã¦èãã¦ã¿ã¾ãããã
ããã® .next_string ã¯ãã®<a>ã¿ã°ã«ãã£ã¦åå²ãããæã®å¾ãã®é¨åã®æå­åã§ãã(?):
last_a_tag = soup.find("a", id="link3")
last_a_tag
# <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>

last_a_tag.next_sibling
# '; and they lived at the bottom of a well.'


ä¸æ¹ã .next_element ã¯ã<a>ã¿ã°ã®ããå¾ãã®è¦ç´ ã§ãã”Tillie”ã¨ããåèªãæãç¤ºãã¾ããæã®æ®ãã®é¨åã§ã¯ããã¾ããã:
last_a_tag.next_element
# u'Tillie'


ããã¯åã®æç« ã§”Tillie”ã¨ããåèªãã»ãã³ã­ã³ã®åã«ç¾ããããã§ãã
ãã¼ãµã¼ã¯<a>ã¿ã°ã«åºä¼ããæ¬¡ã«”Tillie”ã¨ããåèªãããã¦</a>ã¨ããéããã¿ã°ããã¾ãã
ãã®ãã¨ã¯ãã»ãã³ã­ã³ããã£ã¦ãæã®æ®ãã®é¨åã§ãã
ã»ãã³ã­ã³ã¯<a>ã¿ã°ã¨åãã¬ãã«ã«ããã¾ããã”Tillie”ã¨ããåèªãæåã«åºä¼ãã¾ãã
.previous_element å±æ§ã¯ã .next_element ã¨ã¯éã§ãã
ãã®è¦ç´ ã®ä¸ã¤åã®è¦ç´ ãæãç¤ºãã¾ãã:
last_a_tag.previous_element
# u' and\n'
last_a_tag.previous_element.next_element
# <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>




.next_elements / .previous_elementsÂ¶
ãã¼ã¹ããããã­ã¥ã¡ã³ãã®è¦ç´ ããåå¾æ¹åã«åå¾ãã¦ããã¤ãã¬ã¼ã¿ã¼ãä½¿ããã¨ãã§ãã¾ãã:
for element in last_a_tag.next_elements:
    print(repr(element))
# u'Tillie'
# u';\nand they lived at the bottom of a well.'
# u'\n\n'
# <p class="story">...</p>
# u'...'
# u'\n'
# None






ãã¼ã¹ããªã¼ãæ¤ç´¢Â¶
Beautiful Soupã¯ãã¼ã¹ãã¼ã¹ããªã¼ãæ¤ç´¢ããå¤ãã®ã¡ã½ãããå®ç¾©ãã¦ãã¾ãã
ãããããããã¯ã©ããã¨ã¦ãä¼¼éã£ã¦ãã¾ãã
ãã®ç« ã§ã¯ãfind() ã¨ find_all() ã¨ãã2ã¤ã®äººæ°ã®ã¡ã½ããã®èª¬æã«ãå¤ãã®ã¹ãã¼ã¹ãè²»ããã¾ãã
ããä»¥å¤ã®ã¡ã½ããã¯ãã»ã¨ãã©åãå¼æ°ãæã¤ã®ã§ãç°¡åãªèª¬æã«ã¨ã©ãããã¨ã«ãã¾ãã
ããã§ã¯åã³ã”three sisters”ãã­ã¥ã¡ã³ããä¾ã«ä½¿ã£ã¦ããã¾ãã:
html_doc = """
<html><head><title>The Dormouse's story</title></head>

<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""

from bs4 import BeautifulSoup
soup = BeautifulSoup(html_doc)


find_all() ã®ãããªãã£ã«ã¿ã¼ãéããã¨ã«ããã
èå³ã®ãããã­ã¥ã¡ã³ãã®ããä¸é¨åã«ãºã¼ã ãããã¨ãã§ãã¾ãã

ãã£ã«ã¿ã¼ã®ç¨®é¡Â¶
find_all() ç­ã®ã¡ã½ããã®è©³ç´°ãèª¬æããã¾ãã«ããããã®ã¡ã½ããã«æ¸¡ããã£ã«ã¿ã¼ã®ä¾ãç¤ºãã¾ãã
æ¤ç´¢APIã®ä½¿ãæ¹ããã¹ã¿ã¼ããä¸ã§ããã£ã«ã¿ã¼ã¯ä½åº¦ãã§ã¦ãã¾ãã
ããã«ãããã¿ã°å, ã¿ã°ã®å±æ§, ãã­ã¥ã¡ã³ãã®æå­åããããçµã¿åãããæ¡ä»¶ãæå®ãã¦ããã£ã«ã¿ã¼ãããã¾ã

æå­åÂ¶
ãã£ã¨ãã·ã³ãã«ãªãã£ã«ã¿ã¼ã¯æå­åã§ãã
æ¤ç´¢ã¡ã½ããã«æå­åãæ¸¡ãã¨ãBeautiful Soupã¯å³æ ¼ã«æå­åãä¸è´ããã¾ãã
ä»¥ä¸ã®ã³ã¼ãã¯ããã­ã¥ã¡ã³ãåã®<b>ã¿ã°ãå¨ã¦è¦ã¤ãã¾ãã:
soup.find_all('b')
# [<b>The Dormouse's story</b>]


ãã¤ãæå­åãæ¸¡ãã¨ãBeautiful Soupã¯ãããUTF-8ã«ã¨ã³ã³ã¼ããããæå­åã¨ãã¦æ±ãã¾ãã
ãããé¿ããã«ã¯ãä»£ããã«Unicodeæå­åãæ¸¡ãã¾ãã


æ­£è¦è¡¨ç¾Â¶
æ­£è¦è¡¨ç¾ãªãã¸ã§ã¯ããæ¸¡ãã¨ãBeautiful Soupã¯ããã® match() ã¡ã½ãããç¨ãã¦ããã®æ­£è¦è¡¨ç¾ã«ä¸è´ãããã®ããããããã¾ãã
ä»¥ä¸ã®ã³ã¼ãã¯ãå¨ã¦ã®”b”ã§ã¯ãã¾ãã¤ã¥ãã®ååã®ã¿ã°ãè¦ã¤ãã¾ãã
“three sisters”ãã­ã¥ã¡ã³ãã§ã¯ã<body>ã¿ã°ã¨<b>ã¿ã°ã«ããããã¾ãã:
import re
for tag in soup.find_all(re.compile("^b")):
    print(tag.name)
# body
# b


ä»¥ä¸ã®ã³ã¼ãã§ã¯ãã¿ã°åã«”t”ã®ã¤ã¥ããå«ããã®å¨ã¦ãè¦ã¤ãã¾ãã:
for tag in soup.find_all(re.compile("t")):
    print(tag.name)
# html
# title




ãªã¹ãÂ¶
ãã£ã«ã¿ã¼ã«ãªã¹ãã§å¼æ°ããããã¨ãBeautiful Soupã¯ãã®ãªã¹ãã®åã®ããããã«ãããããè¦ç´ ãè¿ãã¾ãã
ä»¥ä¸ã®ã³ã¼ãã¯ãå¨ã¦ã®<a>ã¿ã°ã¨<b>ã¿ã°ãè¦ã¤ãã¾ãã:
soup.find_all(["a", "b"])
# [<b>The Dormouse's story</b>,
#  <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]




Trueå¤Â¶
Trueå¤ ã¯å¨ã¦ã®è¦ç´ ã«ããããã¾ãã
ä»¥ä¸ã®ã³ã¼ãã¯ããã­ã¥ã¡ã³ãåã® å¨ã¦ ã®ã¿ã°ãã¿ã¤ãã¾ãã
ãã ãããã­ã¥ã¡ã³ãæ¬æã®ãã­ã¹ãæå­åã¯ãããããã¾ããã:
for tag in soup.find_all(True):
    print(tag.name)
# html
# head
# title
# body
# p
# b
# p
# a
# a
# a
# p




é¢æ°Â¶
ä»¥ä¸ã®ãã£ã«ã¿ã¼ã§æ©è½ãè¶³ããªãã¨ãã¯ãèªåã§å¼æ°ã«è¦ç´ ãã¨ãé¢æ°ãå®ç¾©ãããã¨ãã§ãã¾ãã
ãã®é¢æ°ã¯ãå¼æ°ããããããã¨ãã¯ True ããããã§ãªãã¨ãã¯ False ãè¿ãã¾ãã
ä»¥ä¸ã®é¢æ°ã§ã¯ãHTMLã¿ã°ã “class” å±æ§ãæã¡ã”id”å±æ§ãæããªãå ´åã« True ãè¿ãã¾ãã:
def has_class_but_no_id(tag):
    return tag.has_attr('class') and not tag.has_attr('id')


ãã®é¢æ°ã find_all() ã«æ¸¡ãã¨ã”three sisters”ãã­ã¥ã¡ã³ãããå¨ã¦ã®<p>ã¿ã°ãåå¾ã§ãã¾ãã:
soup.find_all(has_class_but_no_id)
# [<p class="title"><b>The Dormouse's story</b></p>,
#  <p class="story">Once upon a time there were...</p>,
#  <p class="story">...</p>]


ãã®é¢æ°ã¯<p>ã¿ã°ã ããæ½åºãã¾ãã
<a>ã¿ã°ã¯”class”ã¨”id”ã®ä¸¡æ¹ã®å±æ§ãå®ç¾©ãã¦ããã®ã§æ½åºã§ãã¾ããã
<html>ã<title>ã®ãããªã¿ã°ã¯ã”class”ãå®ç¾©ãã¦ãªãã®ã§ãåæ§ã«æ½åºã§ãã¾ããã
ä»¥ä¸ã®é¢æ°ã¯ãHTMLã¿ã°ãstringãªãã¸ã§ã¯ãã«å²ã¾ãã¦ããã¨ãã¯ã True ãè¿ãã¾ãã(?):
from bs4 import NavigableString
def surrounded_by_strings(tag):
    return (isinstance(tag.next_element, NavigableString)
            and isinstance(tag.previous_element, NavigableString))

for tag in soup.find_all(surrounded_by_strings):
    print tag.name
# p
# a
# a
# a
# p


ããã§æ¤ç´¢ã¡ã½ããã®è©³ç´°ãã¿ã¦ãããã¨ã®æºåãã§ãã¾ããã



find_all()Â¶
ä½¿ãæ¹: find_all(name, attrs, recursive, text, limit, **kwargs)
find_all() ã¡ã½ããã¯ãTag ãªãã¸ã§ã¯ããæã¤å­å­«è¦ç´ ã®ãã¡ãå¼æ°ã«ä¸è´ãã å¨ã¦ã® è¦ç´ ãè¦ã¤ãã¾ãã
ãã£ã«ã¿ã¼ã®ç¨®é¡ ã§ããã¤ãã®ä¾ãæãã¾ããããããã§ããå°ãèª¬æãã¾ãã:
soup.find_all("title")
# [<title>The Dormouse's story</title>]

soup.find_all("p", "title")
# [<p class="title"><b>The Dormouse's story</b></p>]

soup.find_all("a")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

soup.find_all(id="link2")
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]

import re
soup.find(text=re.compile("sisters"))
# u'Once upon a time there were three little sisters; and their names were\n'


ãããã®ä½¿ãæ¹ã¯ããã§ã«èª¬æãã¦ããã®ãããã°ãååºã®ãã®ãããã¾ãã
text ã id ã«å¤ãæ¸¡ãã®ã¯ã©ãããæå³ã§ããããï¼
ãªããfind_all("p", "title") ã¯ãCSSã®”title”ã¿ã°ããã¤<p>ã¿ã°ãçºè¦ããã®ã§ããããï¼
find_all() ã®å¼æ°ãã¿ã¦ããã¾ãããã

nameå¼æ°Â¶
find_all() ã® name å¼æ°ã«å¤ãæ¸¡ãã¨ãã¿ã°ã®ååã ããå¯¾è±¡ã«æ¤ç´¢ãè¡ããã¾ãã
ååããããããªãã¿ã°ã¨åãããã«ããã­ã¹ãæå­åã¯ç¡è¦ããã¾ãã
ä»¥ä¸ã®ä¾ã¯ããã£ã¨ãã·ã³ãã«ãªä½¿ãæ¹ã§ãã:
soup.find_all("title")
# [<title>The Dormouse's story</title>]


ãã£ã«ã¿ã¼ã®ç¨®é¡ ã§è¿°ã¹ãããã«ã name å¼æ°ã¯æå­å, æ­£è¦è¡¨ç¾, ãªã¹ã, é¢æ°, Trueå¤ãã¨ããã¨ãã§ãã¾ãã


ã­ã¼ã¯ã¼ãå¼æ°Â¶
ã©ã®ãããªçè§£ã§ããªãå¼æ°ã§ããã¿ã°ã®å±æ§ã®ä¸ã¤ã¨ãã¦è§£éããã¾ãã
ã­ã¼ã¯ã¼ãå¼æ° id ã«å¤ãæ¸¡ãã¨ãBeautiful Soupã¯ã¿ã°ã®’id’å±æ§ã«å¯¾ãã¦ãã£ã«ã¿ãªã³ã°ãè¡ãã¾ãã:
soup.find_all(id='link2')
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]


ã­ã¼ã¯ã¼ãå¼æ° href ã«å¤ãæ¸¡ãã¨ãBeautiful Soupã¯HTMLã¿ã°ã®’href’å±æ§ã«å¯¾ãã¦ãã£ã«ã¿ãªã³ã°ãè¡ãã¾ãã:
soup.find_all(href=re.compile("elsie"))
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]


ã­ã¼ã¯ã¼ãå¼æ°ã®å¤ãã¾ãã æå­å, æ­£è¦è¡¨ç¾, ãªã¹ã, é¢æ°, Trueå¤ ãã¨ããã¨ãã§ãã¾ãã
æ¬¡ã®ã³ã¼ãã¯ãid å±æ§ã«å¤ãå¥ã£ã¦ããå¨ã¦ã®ã¿ã°ãè¦ã¤ãã¾ãããã®ã¨ããå¤ã¯ä½ã§ããã£ã¦ãæ§ãã¾ããã:
soup.find_all(id=True)
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]


è¤æ°ã®ã­ã¼ã¯ã¼ãå¼æ°ãä¸åº¦ã«æ¸¡ããã¨ã«ãã£ã¦ãè¤æ°ã®å±æ§ã«ã¤ãã¦ãã£ã«ã¿ãªã³ã°ã§ãã¾ãã:
soup.find_all(href=re.compile("elsie"), id='link1')
# [<a class="sister" href="http://example.com/elsie" id="link1">three</a>]


HTML5ã® ‘data-*’ å±æ§ãªã©ãããã¤ãã®å±æ§ã«ã¤ãã¦ã¯ã­ã¼ã¯ã¼ãå¼æ°ã¨ãã¦ç¨ãããã¨ãã§ãã¾ããã:
data_soup = BeautifulSoup('<div data-foo="value">foo!</div>')
data_soup.find_all(data-foo="value")
# SyntaxError: keyword can't be an expression


ãããããããã®å±æ§ãè¾æ¸ã«ãã¦ãã­ã¼ã¯ã¼ãå¼æ° attrs ã¨ãã¦å¤ãæ¸¡ãã°ãã£ã«ã¿ãªã³ã°ãããã¨ãã§ãã¾ãã:
data_soup.find_all(attrs={"data-foo": "value"})
# [<div data-foo="value">foo!</div>]




CSSã®ã¯ã©ã¹ã§æ¤ç´¢Â¶
HTMLã¿ã°ãæã¤CSSã®ã¯ã©ã¹ã§æ¤ç´¢ããããã®ã¯ã¨ã¦ãä¾¿å©ã§ãã
ããã”class”ã¯Pythonã®äºç´èªã®ãããclass ãã­ã¼ã¯ã¼ãå¼æ°ã¨ãã¦ç¨ããã¨ææ³ã¨ã©ã¼ã«ãªãã¾ãã
ããã§ãBeautiful Soup 4.1.2ããã¯ã class_ ã¨ããã­ã¼ã¯ã¼ãå¼æ°ã§CSSã®ã¯ã©ã¹ãæ¤ç´¢ã§ããããã«ãªãã¾ããã:
soup.find_all("a", class_="sister")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]


ä»ã®ã­ã¼ã¯ã¼ãå¼æ°ã¨åæ§ã class_ ã«ã¯æå­å, æ­£è¦è¡¨ç¾, é¢æ°, Trueå¤ãæ¸¡ãã¾ãã:
soup.find_all(class_=re.compile("itl"))
# [<p class="title"><b>The Dormouse's story</b></p>]

def has_six_characters(css_class):
    return css_class is not None and len(css_class) == 6

soup.find_all(class_=has_six_characters)
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]


Tag ãªãã¸ã§ã¯ãã®å±æ§ã® å¤ãè¤æ°ã®ã¨ã ãæãåºãã¦ãã ããã
ããã¨åæ§ã«ãããCSSã¯ã©ã¹ãæ¤ç´¢ããã¨ãã¯ãè¤æ°ã®CSSã¯ã©ã¹ã«å¯¾ãã¦ãããããããã¾ãã:
css_soup = BeautifulSoup('<p class="body strikeout"></p>')
css_soup.find_all("p", class_="strikeout")
# [<p class="body strikeout"></p>]

css_soup.find_all("p", class_="body")
# [<p class="body strikeout"></p>]


class å±æ§ã®å¤ã¯ãæå­åã¨ãã¦ãæ¤ç´¢ã§ãã¾ãã:
css_soup.find_all("p", class_="body strikeout")
# [<p class="body strikeout"></p>]


ããããæå­åã®å¤ã¨ãã¦ã®å¤æ°ãæ¤ç´¢ãããã¨ã¯ã§ãã¾ããã:
css_soup.find_all("p", class_="strikeout body")
# []


ããããªãã2ã¤ä»¥ä¸ã®ã¯ã©ã¹ãã¾ã£ã¡ãããããªããCSSã»ã¬ã¯ããä½¿ã£ã¦ãã ããã:
css_soup.select("p.strikeout.body")
# [<p class="body strikeout"></p>]


Beautiful Soupã®å¤ããã¼ã¸ã§ã³ã§ã¯ã class_ å¼æ°ã¯ä½¿ãã¾ããã
ããã§ãä»¥ä¸ã«è¿°ã¹ã attrs ããªãã¯ãä½¿ããã¨ãã§ãã¾ãã
ããã¯”class”ãkeyã«æã¤è¾æ¸ã attrs å¼æ°ã«æ¸¡ãã¦ãæ¤ç´¢ãããã¨ãã§ãã¾ãã
ãã®è¾æ¸ã®valueã«ã¯ãæå­å, æ­£è¦è¡¨ç¾ãªã©ãä½¿ãã¾ãã:
soup.find_all("a", attrs={"class": "sister"})
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]




textå¼æ°Â¶
text å¼æ°ã§ãã¿ã°ã«æã¾ãã¦ããæå­åãå¯¾è±¡ã«æ¤ç´¢ãããã¨ãã§ãã¾ãã
name å¼æ°ãã­ã¼ã¯ã¼ãå¼æ°ã®ããã«ã æå­å , æ­£è¦è¡¨ç¾ , ãªã¹ã , é¢æ° , Trueå¤ ãä½¿ãã¾ãã
ä»¥ä¸ã®ä¾ãããããã ããã:
soup.find_all(text="Elsie")
# [u'Elsie']

soup.find_all(text=["Tillie", "Elsie", "Lacie"])
# [u'Elsie', u'Lacie', u'Tillie']

soup.find_all(text=re.compile("Dormouse"))
[u"The Dormouse's story", u"The Dormouse's story"]

def is_the_only_string_within_a_tag(s):
    """Return True if this string is the only child of its parent tag."""
    return (s == s.parent.string)

soup.find_all(text=is_the_only_string_within_a_tag)
# [u"The Dormouse's story", u"The Dormouse's story", u'Elsie', u'Lacie', u'Tillie', u'...']


text å¼æ°ã¯ãã­ã¹ãæå­åã®æ¤ç´¢ã§ãããããã«ã¿ã°ã®æ¤ç´¢ãçµã¿ããããã¨ãã§ãã¾ãã
Beautiful Soupã¯ãtext å¼æ°ã§æå®ããæå­åã .string ã«ãã¤ã¿ã°å¨ã¦ãè¦ã¤ãã¾ãã
æ¬¡ã®ã³ã¼ãã¯ã.string ã« “Elsie”ãæã¤<a>ã¿ã°ãè¦ã¤ãã¾ãã:
soup.find_all("a", text="Elsie")
# [<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>]




limitå¼æ°Â¶
find_all() ã¡ã½ããã¯ãæå®ãããã£ã«ã¿ã¼ã«ãããããå¨ã¦ã®ã¿ã°ã¨æå­åãè¿ãã¾ãã
ããã¯ãã­ã¥ã¡ã³ããå¤§ããã¨ãã¯æéããããã¾ãã
ããã å¨ã¦ã® çµæãå¿è¦ã¨ããªããã°ãlimit å¼æ°ã§åå¾ããæ°ãæå®ãããã¨ãã§ãã¾ãã
“three siters”ãã­ã¥ã¡ã³ãã«ã¯3ã¤ã®ãªã³ã¯ãããããããä»¥ä¸ã®ã³ã¼ãã¯ã¯ããã®2ã¤ããè¦ã¤ããªãã:
soup.find_all("a", limit=2)
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]




recursiveå¼æ°Â¶
mytag.find_all() ãå®è¡ããã¨ãBeautiful Soupã¯ã mytag ã®å¨ã¦ã®å­å­«è¦ç´ ãèª¿ã¹ã¾ãã
(å­è¦ç´ ãå­è¦ç´ ã®å­è¦ç´ ããã®ã¾ãå­è¦ç´ ã¨ãããããã§ãã)
ãããç´ä¸ã®å­è¦ç´ ããèª¿ã¹ãããªããã°ãrecursive=False ã¨ããå¼æ°ãæ¸¡ãã°ããã§ãã
ä»¥ä¸ã§éããã¿ã¦ã¿ã¾ãããã:
soup.html.find_all("title")
# [<title>The Dormouse's story</title>]

soup.html.find_all("title", recursive=False)
# []


ããã¯ãã­ã¥ã¡ã³ãã®ä¸é¨ã§ãã:
<html>
 <head>
  <title>
   The Dormouse's story
  </title>
 </head>
...

ãã®ãã­ã¥ã¡ã³ãã«ããã¦ã<title>ã¿ã°ã¯<html>ã®ä¸ã«ã¯ããããç´ä¸ ã«ããããã§ã¯ããã¾ããã
Beautiful Soupã<title>ã¿ã°ãè¦ã¤ãããã¨ãã§ããã®ã¯ã<html>ã¿ã°ä»¥ä¸ã®å¨ã¦ã®å­å­«è¦ç´ ãæ¢ãã¦ããã¨ãã ãã§ãã
ãããfind_all() ã®å¼æ°ã« recurive=False ã¨ãã<html>ã¿ã°ã®ç´ä¸ã®ã¿ãæ¤ç´¢ããã¨ããå¶éãããã£ã¦ãããã<title>ã¿ã°ãè¦ã¤ãããã¨ã¯ã§ãã¾ããã
Beautiful Soupã¯ãå¤ãã®ãã¼ã¹ããªã¼ãæ¤ç´¢ããã¡ã½ãããæä¾ãã¦ãã¾ãã
ãããå¤ãã¯å±éããå¼æ°ãæã¡ã¾ãã
find_all() ã® name, attrs, text, limit, ã­ã¼ã¯ã¼ãå¼æ°ã¯ãä»ã®å¤ãã®ã¡ã½ããã«ãå¯¾å¿ãã¦ãã¾ãã
ãããã recursive å¼æ°ã¯ã find_all(), find() ã®2ã¤ã®ã¡ã½ããããå¯¾å¿ãã¦ãã¾ããã
find_parents() ã®ãããªã¡ã½ããã«ãå¼æ° recursive=False ãæ¸¡ãã¦ãæå³ãããã¾ããã


ã·ã§ã¼ãã«ããÂ¶
find_all() ã¯Beautiful Soupã®æ¤ç´¢APIã®ä¸­ã§ãä¸çªä½¿ããããã®ãªã®ã§ãã·ã§ã¼ãã«ãããããã¾ãã
Beautiful Soup ãªãã¸ã§ã¯ãã Tag ãªãã¸ã§ã¯ããé¢æ°ã®ããã«æ±ã£ã¦ã find_all() ã¡ã½ãããå¼ã³åºããã¨ãã§ãã¾ãã
ä»¥ä¸ã®2è¡ã¯ç­ä¾¡ã§ãã:
soup.find_all("a")
soup("a")


ä»¥ä¸ã®2è¡ãã¾ãç­ä¾¡ã§ãã:
soup.title.find_all(text=True)
soup.title(text=True)





find()Â¶
ä½¿ãæ¹: find(name, attrs, recursive, text, **kwargs)
find_all() ã¡ã½ããã¯ãæ¤ç´¢çµæãå¾ãããã«HTMLãã­ã¥ã¡ã³ãå¨é¨ãã¹ã­ã£ã³ãã¾ãã
ãããã1ã¤ã ãã®æ¤ç´¢çµæãå¿è¦ãªã¨ããããã¾ãã
ãããHTMLãã­ã¥ã¡ã³ãã«<body>ã¿ã°ã1ã¤ã ããªããHTMLãã­ã¥ã¡ã³ãå¨ä½ãã¹ã­ã£ã³ããã®ã¯æéã®ç¡é§ã§ãã
ãã®å ´åã¯ find_all() ã¡ã½ããã« limit=1 ã¨ããå¼æ°ãæ¸¡ããã«ã find() ã¡ã½ãããä½¿ããã¨ãã§ãã¾ãã
ä»¥ä¸ã®2è¡ã¯ãã»ã¼ç­ä¾¡ã§ãã:
soup.find_all('title', limit=1)
# [<title>The Dormouse's story</title>]

soup.find('title')
# <title>The Dormouse's story</title>


ãã 1ã¤éãç¹ã¯ãfind_all() ã¯è¦ç´ 1ã®ãªã¹ããè¿ããfind() ã¯è¦ç´ ããã®ã¾ã¾è¿ããã¨ã§ãã
find_all() ãä½ãã¿ã¤ããããªãã¨ãã¯ç©ºãªã¹ããè¿ãã¾ãã
find() ãä½ãã¿ã¤ããããªãã¨ãã¯ã None ãè¿ãã¾ãã:
print(soup.find("nosuchtag"))
# None


ã¿ã°åã§æ¢ç´¢ ã§åºã¦ãã soup.head.title ã§æ¢ç´¢ããæ¹æ³ãè¦ãã¦ãã¾ããï¼ ãï½ãã¯ãfind() ã«ã¤ãã¦ãé©ç¨ã§ãã¾ãã:
soup.head.title
# <title>The Dormouse's story</title>

soup.find("head").find("title")
# <title>The Dormouse's story</title>




find_parents() / find_parent()Â¶
ä½¿ãæ¹: find_parents(name, attrs, text, limit, **kwargs)
ä½¿ãæ¹: find_parent(name, attrs, text, **kwargs)
ããã¾ã§ find_all() ã¨ find() ã«ã¤ãã¦è¿°ã¹ã¦ãã¾ããã
Beautiful Soup APIã«ã¯ãã¼ã¹ããªã¼ãæ¤ç´¢ããããã®ã¡ã½ãããããã¨10ããã¾ãã
ããããããããå¿è¦ã¯ããã¾ããã
ãã®ãã¡5ã¤ã¯ãfind_all() ã¨åºæ¬çã«åãã§ãã
ããã¦ãã®ããã®5ã¤ã¯ find() ã¨åºæ¬çã«åãã§ãã
éãã¯ãããªã¼ã®ã©ã®é¨åãæ¤ç´¢å¯¾è±¡ã«ããã®ãã¨ããç¹ã®ã¿ã§ãã
æåã«ã find_parents() ã¨ find_parent() ãè¦ã¦ã¿ã¾ãããã
find_all() ã¨ find() ãã¿ã°ã®å­å­«ãè¦ã¦ãããªã¼ãä¸ãã¦ãã£ããã¨ãæãåºãã¦ãã ããã
find_parents() ã¨ find_parent() ã¯éã§ãã
ãããã¯ã¿ã°ãæå­åã®è¦ªãã¿ã¦ãããªã¼ã’ä¸ã«’æ¤ç´¢ãã¦ããã¾ãã
ä»¥ä¸ã®”three daughters”ãã­ã¥ã¡ã³ãã®ä¾ã§ãæ·±ãã¬ãã«ã«ããæå­åããæ¤ç´¢ãã¦ããæ§å­ãè¦ã¦ãã ããã:
a_string = soup.find(text="Lacie")
a_string
# u'Lacie'

a_string.find_parents("a")
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]

a_string.find_parent("p")
# <p class="story">Once upon a time there were three little sisters; and their names were
#  <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a> and
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>;
#  and they lived at the bottom of a well.</p>

a_string.find_parents("p", class="title")
# []

3ã¤ã®<a>ã¿ã°ã®ãã¡ã®1ã¤ã¯ãæ¤ç´¢ã®èµ·ç¹ã«ãªãæå­åã®ç´æ¥ã®è¦ªè¦ç´ ãªã®ã§ããããè¿ããã¾ããã
3ã¤ã®<p>ã¿ã°ã®ãã¡ã®1ã¤ã¯ãèµ·ç¹ã®æå­åã®ç´æ¥ã®è¦ªã§ã¯ããã¾ãããããã¯ããããè¿ããã¾ããã
CSSã¯ã©ã¹”title”ããã¤<p>ã¿ã°ã¯ã”three daughers”ãã­ã¥ã¡ã³ãä¸­ã«ã¯ããã®ã§ãããèµ·ç¹ã®æå­åã®è¦ªè¦ç´ ã§ã¯ãªãã®ã§ã find_parents() ã§ã¯è¦ã¤ãããã¨ãã§ãã¾ããã§ããã
find_parent() ã¨ find_parents() ã®ã¤ãªããã¯ããã£ãã§ããããã
.parent ã¨ .parents å±æ§ã«ã¤ãã¦ã¯ãä»¥åã«è¿°ã¹ã¦ããã¾ãã
ãã®ã¤ãªããã¯ã¨ã¦ãå¼·ãã§ãã
ãããã®æ¤ç´¢ã¡ã½ããã¯å®éã«ã¯ .parents ã§ãå¨ã¦ã®è¦ªè¦ç´ ã®é£ãªããã¤ãã¬ã¼ããã¦æ±ãã¾ãã
ããã¦ãè¦ç´ ããããã«ã¤ãã¦ãã£ã«ã¿ã¼ã«ããããããã©ããããã§ãã¯ãã¾ãã


find_next_siblings() / find_next_sibling()Â¶
ä½¿ãæ¹: find_next_siblings(name, attrs, text, limit, **kwargs)
ä½¿ãæ¹: find_next_sibling(name, attrs, text, **kwargs)
ãããã®ã¡ã½ããã¯ãå¾æ¹ã«ããåå¼è¦ç´ ãæ±ãã®ã«ã .next_siblings ãä½¿ãã¾ãã
find_next_siblings() ã¡ã½ããã¯ãããããåå¼è¦ç´ ãå¨ã¦è¿ãã find_next_sibling() ã¯æåã®ä¸ã¤ãè¿ãã¾ãã:
first_link = soup.a
first_link
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>

first_link.find_next_siblings("a")
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

first_story_paragraph = soup.find("p", "story")
first_story_paragraph.find_next_sibling("p")
# <p class="story">...</p>




find_previous_siblings() / find_previous_sibling()Â¶
ä½¿ãæ¹: find_previous_siblings(name, attrs, text, limit, **kwargs)
ä½¿ãæ¹: find_previous_sibling(name, attrs, text, **kwargs)
ãããã®ã¡ã½ããã¯ãHTMLãã­ã¥ã¡ã³ãã®åæ¹ã«ãã£ãåå¼è¦ç´ ãæ±ãã®ã« .previous_siblings ãä½¿ãã¾ãã
find_previous_siblings() ã¡ã½ããã¯ãããããåå¼è¦ç´ ãå¨ã¦è¿ãã find_previous_sibling() ã¯æåã®ä¸ã¤ãè¿ãã¾ãã:
last_link = soup.find("a", id="link3")
last_link
# <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>

last_link.find_previous_siblings("a")
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]

first_story_paragraph = soup.find("p", "story")
first_story_paragraph.find_previous_sibling("p")
# <p class="title"><b>The Dormouse's story</b></p>




find_all_next() / find_next()Â¶
ä½¿ãæ¹: find_all_next(name, attrs, text, limit, **kwargs)
ä½¿ãæ¹: find_next(name, attrs, text, **kwargs)
ãããã®ã¡ã½ããã¯ãHTMLãã­ã¥ã¡ã³ãã®ãã®å¾ã«ãããããã¿ã°ã¨æå­åã®è¦ç´ å¨ã¦ã¤ãã¬ã¼ããã¦æ±ãããã«ã .next_elements ã¡ã½ãããä½¿ãã¾ãã
find_all_next() ã¡ã½ããã¯ããããããã®å¨ã¦ãè¿ãã find_next() ã¯æåã«ããããããã®ãè¿ãã¾ãã(!è¦æ¹å):
first_link = soup.a
first_link
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>

first_link.find_all_next(text=True)
# [u'Elsie', u',\n', u'Lacie', u' and\n', u'Tillie',
#  u';\nand they lived at the bottom of a well.', u'\n\n', u'...', u'\n']

first_link.find_next("p")
# <p class="story">...</p>


æåã®ä¾ã§ã¯ãèµ·ç¹ã¨ãªã£ã<a>ã¿ã°ã«æã¾ãã¦ãããæå­å”Elsie”ãè¿ããã¦ãã¾ãã
ï¼çªãã®ä¾ã§ã¯ãèµ·ç¹ã¨ãªã£ã<a>ã¿ã°ã¨åããã¼ããããªãã«ãé¢ããããæå¾ã®<p>ã¿ã°ãç¤ºããã¦ãã¾ãã
ãããã®ã¡ã½ããã§ã¯ãåé¡ã¯ãã£ã«ã¿ã¼ã«ããããããå¦ãã¨ãã¹ã¿ã¼ãããè¦ç´ ãããå¾ã«ã§ã¦ãããã¨ãããã¨ãåããã¾ãã(!è¦æ¹å)


find_all_previous() / find_previous()Â¶
ä½¿ãæ¹: find_all_previous(name, attrs, text, limit, **kwargs)
ä½¿ãæ¹: find_previous(name, attrs, text, **kwargs)
ãããã®ã¡ã½ããã¯ããã­ã¥ã¡ã³ãã®èµ·ç¹ã®ã¿ã°ã®åã«ãããããã¿ã°ã¨æå­åã®è¦ç´ å¨ã¦ãã¤ãã¬ã¼ããã¦æ±ãããã«ã .previous_elements ã¡ã½ãããä½¿ãã¾ãã(!è¦æ¹å):
first_link = soup.a
first_link
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>

first_link.find_all_previous("p")
# [<p class="story">Once upon a time there were three little sisters; ...</p>,
#  <p class="title"><b>The Dormouse's story</b></p>]

first_link.find_previous("title")
# <title>The Dormouse's story</title>


find_all_previous("p") ã¯”three sisters”ãã­ã¥ã¡ã³ãã®æåã®æ®µè½ãè¦ã¤ãã¾ãã(class=”title”ã®ãã¤ã§ã)
ããããç¬¬ï¼æ®µè½ã§ãè¦ã¤ãã¾ãã<p>ã¿ã°ã¯åã«èµ·ç¹ã«ãã<a>ã¿ã°ãå«ãã§ãã¾ãã
é©ããããªãã§ãã ããã
æãã¯ãèµ·ç¹ã®ã¿ã°ããåæ¹ã«ç¾ããå¨ã¦ã®ã¿ã°ãè¦ã¦ããã®ã§ãã<a>ã¿ã°ãæãã§ãã<p>ã¿ã°ã¯ã<a>ã¿ã°ãããåã«ç¤ºããã­ã°ãªãã¾ããã(!è¦æ¹å)


CSSã»ã¬ã¯ã¿Â¶
Beautiful Soupã¯ãããä½¿ãããCSSã»ã¬ã¯ã¿ãã»ã¨ãã©ãµãã¼ããã¦ãã¾ãã
Tag ãªãã¸ã§ã¯ãã BeautifulSoup ãªãã¸ã§ã¯ãã« .select() ã¡ã½ããã§æå­åãæ¸¡ãã ãã§ä½¿ãã¾ãã
ã¿ã°ãè¦ã¤ããã«ã¯æ¬¡ã®ããã«ãã¾ãã:
soup.select("title")
# [<title>The Dormouse's story</title>]

soup.select("p nth-of-type(3)")
# [<p class="story">...</p>]


ããã¿ã°ããå¾ãã®æå®ãããã¿ã°ãè¦ã¤ãã¾ãã:
soup.select("body a")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie"  id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

soup.select("html head title")
# [<title>The Dormouse's story</title>]


ããã¿ã°ã®ç´å¾ã®æå®ãããã¿ã°ãè¦ã¤ãã¾ãã:
soup.select("head > title")
# [<title>The Dormouse's story</title>]

soup.select("p > a")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie"  id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

soup.select("p > a:nth-of-type(2)")
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]

soup.select("p > #link1")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]

soup.select("body > a")
# []


ã¿ã°ã®åå¼è¦ç´ ãè¦ã¤ãã¾ãã:
soup.select("#link1 ~ .sister")
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie"  id="link3">Tillie</a>]

soup.select("#link1 + .sister")
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]


CSSã¯ã©ã¹ã«ãã£ã¦ã¿ã°ãè¦ã¤ãã¾ãã:
soup.select(".sister")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

soup.select("[class~=sister]")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]


CSSã®IDã«ãã£ã¦ã¿ã°ãè¦ã¤ãã¾ãã:
soup.select("#link1")
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]

soup.select("a#link2")
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]


æå®ã®å±æ§ã®æç¡ã§ã¿ã°ãè¦ã¤ãã¾ãã:
soup.select('a[href]')
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]


å±æ§ãæã¤å¤ã«ãã£ã¦ã¿ã°ãè¦ã¤ãã¾ãã:
soup.select('a[href="http://example.com/elsie"]')
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]

soup.select('a[href^="http://example.com/"]')
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

soup.select('a[href$="tillie"]')
# [<a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

soup.select('a[href*=".com/el"]')
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]


languageã³ã¼ãã§ããããããã¾ãã:
multilingual_markup = """
 <p lang="en">Hello</p>
 <p lang="en-us">Howdy, y'all</p>
 <p lang="en-gb">Pip-pip, old fruit</p>
 <p lang="fr">Bonjour mes amis</p>
"""
multilingual_soup = BeautifulSoup(multilingual_markup)
multilingual_soup.select('p[lang|=en]')
# [<p lang="en">Hello</p>,
#  <p lang="en-us">Howdy, y'all</p>,
#  <p lang="en-gb">Pip-pip, old fruit</p>]


ãã®ããæ¹ã¯ãCSSã»ã¬ã¯ã¿ã®ææ³ãç¥ã£ã¦ããã¦ã¼ã¶ã«ã¨ã£ã¦ã¯ãã¨ã¦ãä¾¿å©ã§ãã
ããã§Beautiful Soup APIã®å¨ã¦ã®ã­ã¢ãä½¿ããããã«ãªãã¾ããã
ããCSSã»ã¬ã¯ã¿ãä½¿ãããªããããªããlxmlãä½¿ã£ã¦ã¿ãã®ãããã§ãããã
lxmlã¯å¦çãã¨ã¦ãéããããã«å¤ãã®CSSã»ã¬ã¯ã¿ããµãã¼ããã¦ãã¾ãã
ããããããã§ã¯Beautiful Soup APIãä½¿ã£ã¦ãã·ã³ãã«ãªCSSã»ã¬ã¯ã¿ã®çµã¿åãããã«ããæ¹æ³ãèª¬æãã¾ããã



ãã¼ã¹ããªã¼ãä¿®æ­£Â¶
Beautiful Soupã®ä¸»ãªå¼·ã¿ã¯ããã¼ã¹ããªã¼ã®æ¤ç´¢ããã¨ããã«ããã¾ãã
ãããã¾ããBeautiful Soupã¯ãããªã¼ãä¿®æ­£ããããå¤æ´ããããªã¼ãæ°ããHTMLãXMLã®ãã­ã¥ã¡ã³ãã«åºåãããã¨ãã§ãã¾ãã

ååãå±æ§ã®å¤æ´Â¶
å±æ§ ã®ç¯ã§ãè¿°ã¹ã¾ããããã¿ã°ã®ååå¤æ´ãå±æ§å¤ã®å¤æ´ãè¿½å ãåé¤ãã§ãã¾ãã:
soup = BeautifulSoup('<b class="boldest">Extremely bold</b>')
tag = soup.b

tag.name = "blockquote"
tag['class'] = 'verybold'
tag['id'] = 1
tag
# <blockquote class="verybold" id="1">Extremely bold</blockquote>

del tag['class']
del tag['id']
tag
# <blockquote>Extremely bold</blockquote>




.string ã®ä¿®æ­£Â¶
Tag ãªãã¸ã§ã¯ãã® .string ãå¤æ´ããã¨ããã®ã¿ã°ãæãæå­åããã®å¤ã«å¤æ´ããã¾ãã:
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup)

tag = soup.a
tag.string = "New link text."
tag
# <a href="http://example.com/">New link text.</a>


æ³¨æç¹: å¤æ´ããã¿ã°ãä»ã®ã¿ã°ãæãã§ããã¨ããããã®ã¿ã°å¨ã¦ãç ´å£ããã¾ãã


append()Â¶
Tag.append() ã«ãããã¿ã°ãæãã§ããæå­åã«è¿½å ããããã¨ãã§ãã¾ãã
ã¾ãã§Pythonã®ãªã¹ãã® .append() ã®ããã«ä½ç¨ãã¾ãã:
soup = BeautifulSoup("<a>Foo</a>")
soup.a.append("Bar")

soup
# <html><head></head><body><a>FooBar</a></body></html>
soup.a.contents
# [u'Foo', u'Bar']




BeautifulSoup.new_string() / .new_tag()Â¶
ãã­ã¥ã¡ã³ãã«æå­åãå ãããã¨ãã¯ãPythonã®æå­åã append() ã«æ¸¡ãã¦ãã ããã
ãããã¯ã factory method ã® BeautifulSoup.new_string() ãå¼åºãã¦ãã ããã:
soup = BeautifulSoup("<b></b>")
tag = soup.b
tag.append("Hello")
new_string = soup.new_string(" there")
tag.append(new_string)
tag
# <b>Hello there.</b>
tag.contents
# [u'Hello', u' there']


æ°ããã³ã¡ã³ãã ä»ã® NavigableString ã®ãµãã¯ã©ã¹ãçæãããã¨ãã¯ã new_string() ã®ç¬¬ï¼å¼æ°ã«ãã®ã¯ã©ã¹ãæ¸¡ãã¦ãã ããã:
from bs4 import Comment
new_comment = soup.new_string("Nice to see you.", Comment)
tag.append(new_comment)
tag
# <b>Hello there<!--Nice to see you.--></b>
tag.contents
# [u'Hello', u' there', u'Nice to see you.']


(ããã¯Beautiful Soup 4.2.1 ã®æ°æ©è½ã§ã)
å®å¨ã«æ°ããã¿ã°ãçæãããã¨ãã¯ãfactory methodã® BeautifulSoup.new_tag() ãå¼ã³åºãã¦ãã ããã:
soup = BeautifulSoup("<b></b>")
original_tag = soup.b

new_tag = soup.new_tag("a", href="http://www.example.com")
original_tag.append(new_tag)
original_tag
# <b><a href="http://www.example.com"></a></b>

new_tag.string = "Link text."
original_tag
# <b><a href="http://www.example.com">Link text.</a></b>


ç¬¬ï¼å¼æ°ã®ã¿ã°åã ãã¯å¿é ã§ãã


insert()Â¶
Tag.insert() ã¯ Tag.append() ã«ä¼¼ã¦ãã¾ãã
éãã®ã¯ãã¿ã°ã® .contents ã®æå¾ä»¥å¤ã«ããè¦ç´ ãæ¿å¥ã§ããã¨ããç¹ã§ãã:
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup)
tag = soup.a

tag.insert(1, "but did not endorse ")
tag
# <a href="http://example.com/">I linked to but did not endorse <i>example.com</i></a>
tag.contents
# [u'I linked to ', u'but did not endorse', <i>example.com</i>]




insert_before() / insert_after()Â¶
insert_before() ã¡ã½ããã¯ãããã¿ã°ã®ç´åã«ãå¥ã®ã¿ã°ãæå­åãæ¿å¥ãã¾ãã:
soup = BeautifulSoup("<b>stop</b>")
tag = soup.new_tag("i")
tag.string = "Don't"
soup.b.string.insert_before(tag)
soup.b
# <b><i>Don't</i>stop</b>


insert_after() ã¡ã½ããã¯ãããã¿ã°ã®ç´å¾ã«ãå¥ã®ã¿ã°ãæå­åãæ¿å¥ãã¾ãã:
soup.b.i.insert_after(soup.new_string(" ever "))
soup.b
# <b><i>Don't</i> ever stop</b>
soup.b.contents
# [<i>Don't</i>, u' ever ', u'stop']




clear()Â¶
Tag.clear() ã¯ãã¿ã°ãæãã§ããcontentsãåé¤ãã¾ãã(è¨³æ³¨:è¦ãã§ãã¯?):
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup)
tag = soup.a

tag.clear()
tag
# <a href="http://example.com/"></a>




extract()Â¶
PageElement.extract() ã¯ããªã¼ããã¿ã°ãæå­åãé¤å»ãã¾ãã
è¿å¤ã¯ããã®æ½åºãããã¿ã°ãæå­åã§ãã:
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup)
a_tag = soup.a

i_tag = soup.i.extract()

a_tag
# <a href="http://example.com/">I linked to</a>

i_tag
# <i>example.com</i>

print(i_tag.parent)
None


ãã®ã¨ãã2ã¤ã®ãã¼ã¹ããªã¼ãããã¾ãã1ã¤ã¯ BeautifulSoup ãªãã¸ã§ã¯ããæ ¹ãã¼ãã¨ããããªãããã¼ã¹ãããã­ã¥ã¡ã³ãã§ãããã1ã¤ã¯ãæ½åºããã¿ã°ãæ ¹ãã¼ãã¨ãããã®ã§ããæ½åºããè¦ç´ ã®å­è¦ç´ ã extract ã§ã³ã¼ã«ã§ãã¾ãã:
my_string = i_tag.string.extract()
my_string
# u'example.com'

print(my_string.parent)
# None
i_tag
# <i></i>




decompose()Â¶
Tag.decompose() ã¯ãã¼ã¹ããªã¼ããã¿ã°ãé¤å»ãã¾ãã
ãã®ã¿ã°ã¨æãã§ããcontentsãå®å¨ã«åé¤ãã¾ã
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup)
a_tag = soup.a

soup.i.decompose()

a_tag
# <a href="http://example.com/">I linked to</a>




replace_with()Â¶
PageElement.replace_with() ã¯ããªã¼ããã¿ã°ã¨æå­åãé¤å»ãã
å¼æ°ã«ä¸ããã¿ã°ãæå­ããã®ä»£ããã«ç½®ãæãã¾ãã:
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup)
a_tag = soup.a

new_tag = soup.new_tag("b")
new_tag.string = "example.net"
a_tag.i.replace_with(new_tag)

a_tag
# <a href="http://example.com/">I linked to <b>example.net</b></a>


replace_with() ã¯ç½®ãæããããã¿ã°ãæå­åãè¿ãã¾ãã
ããããèª¿æ»ããããããªã¼ã®ä»ã®é¨åã«å ãããã¨ãã§ãã¾ãã


wrap()Â¶
PageElement.wrap() ã¯ããã®è¦ç´ ãå¼æ°ã§æå®ããã¿ã°ãæã¿ã¾ãã
æ°ããæã¾ãããã®ãè¿ãã¾ãã
soup = BeautifulSoup("<p>I wish I was bold.</p>")
soup.p.string.wrap(soup.new_tag("b"))
# <b>I wish I was bold.</b>

soup.p.wrap(soup.new_tag("div")
# <div><p><b>I wish I was bold.</b></p></div>

ãã®ã¡ã½ããã¯ãBeautiful Soup 4.0.5 ããã®æ°æ©è½ã§ãã


unwrap()Â¶
Tag.unwrap() ã¯ wrap() ã®åå¯¾ã§ãã
ããã¯ãã¿ã°ã®ä¸­èº«ããªãã§ãããããã¨ã¿ã°ãç½®ãæãã¾ãã
ãã¼ã¯ã¢ãããã¯ããã®ã«ä¾¿å©ã§ãã(è¨³æ³¨ï¼ãããªãã??):
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup)
a_tag = soup.a

a_tag.i.unwrap()
a_tag
# <a href="http://example.com/">I linked to example.com</a>


replace_with() ã®ããã«ã unwrap() ã¯ç½®ãæããããã¿ã°ãè¿ãã¾ãã



åºåÂ¶

ãããã«åºåÂ¶
prettify() ã¡ã½ããã¯ãBeautifulSoupãã¼ã¹ããªã¼ãã1è¡ã«1ã¿ã°ã®ãããã«ãã©ã¼ããããããUnicodeæå­åã«å¤æãã¾ãã:
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup)
soup.prettify()
# '<html>\n <head>\n </head>\n <body>\n  <a href="http://example.com/">\n...'

print(soup.prettify())
# <html>
#  <head>
#  </head>
#  <body>
#   <a href="http://example.com/">
#    I linked to
#    <i>
#     example.com
#    </i>
#   </a>
#  </body>
# </html>


prettify() ã¡ã½ããã¯ã ãããã¬ãã«ã® BeautifulSoup ãªãã¸ã§ã¯ãã§ããããä»¥å¤ã® Tag ãªãã¸ã§ã¯ãã§ãå¼ã³åºããã¨ãã§ãã¾ãã:
print(soup.a.prettify())
# <a href="http://example.com/">
#  I linked to
#  <i>
#   example.com
#  </i>
# </a>




ä¸è¡ã«åºåÂ¶
ãã©ã¼ãããããããã­ã¹ãã§ã¯ãªãåãªãæå­åãã»ãããã°ã BeautifulSoup ã Tag ãªãã¸ã§ã¯ãã® unicode() ã str() ãå¼ã³åºãã¾ãã:
str(soup)
# '<html><head></head><body><a href="http://example.com/">I linked to <i>example.com</i></a></body></html>'

unicode(soup.a)
# u'<a href="http://example.com/">I linked to <i>example.com</i></a>'


str() é¢æ°ã¯ãUTF-8ã«ã¨ã³ã³ã¼ããããæå­åãè¿ãã¾ãã
ä»ã®ãªãã·ã§ã³ãç¥ããããã°ã ã¨ã³ã³ã¼ã  ãã¿ã¦ãã ããã
ãã¤ãæå­åãå¾ãã®ã«ã encode() ãç¨ãããã¨ãã§ãã¾ãã
decode() ãç¨ããã¨ãUnicodeãå¾ããã¨ãã§ãã¾ãã


ãã©ã¼ããããæå®Â¶
Beautiful Soupã«ã”&lquot;”ã®ãããªHTMLã¨ã³ãã£ãã£ãå«ãã ãã­ã¥ã¡ã³ããæ¸¡ãã¨ããããã¯Unicodeã­ã£ã©ã¯ã¿ã«å¤æããã¾ãã:
soup = BeautifulSoup("&ldquo;Dammit!&rdquo; he said.")
unicode(soup)
# u'<html><head></head><body>\u201cDammit!\u201d he said.</body></html>'


ãã®ãã­ã¥ã¡ã³ããæå­åã«å¤æããã¨ãUnicodeæå­åã¯UTF-8ã­ã£ã©ã¯ã¿ã¨ãã¦ã¨ã³ã³ã¼ãããã¾ãã
ããããHTMLã¨ã³ãã£ãã£ã«æ»ããã¨ã¯ã§ãã¾ããã:
str(soup)
# '<html><head></head><body>\xe2\x80\x9cDammit!\xe2\x80\x9d he said.</body></html>'


ããã©ã«ãã§ã¯ãåºåããã¨ãã¨ã¹ã±ã¼ããããã®ã¯ãè£¸ã®&ã¨è§ãã£ãã®ã¿ã§ãã
ãããã¯ã”&amp;”,”&lt;”,”&gt”ã«å¤æããã¾ãã
ãã®ããBeautifulSoupã¯ãã£ããä¸æ­£ç¢ºãªHTMLãXMLãçæãããã¨ã¯ããã¾ããã:
soup = BeautifulSoup("<p>The law firm of Dewey, Cheatem, & Howe</p>")
soup.p
# <p>The law firm of Dewey, Cheatem, &amp; Howe</p>

soup = BeautifulSoup('<a href="http://example.com/?foo=val1&bar=val2">A link</a>')
soup.a
# <a href="http://example.com/?foo=val1&amp;bar=val2">A link</a>


prettify(), encode(), decode() ã® formatter å±æ§ã«å¤ãä¸ããã¨ãåºåãå¤æ´ãããã¨ãã§ãã¾ãã
formatter ã¯ã4ç¨®é¡ã®å¤ãã¨ãå¾ã¾ãã
ããã©ã«ãã§ã¯ã formatter="minimal" ã§ãã
æå­åã¯ãBeautiful Soupãæ­£ããHTML/XMLãçæãããã¨ãååã«ä¿è¨¼ããããã«ãå å·¥ãããã ãã§ãã:
french = "<p>Il a dit &lt;&lt;Sacr&eacute; bleu!&gt;&gt;</p>"
soup = BeautifulSoup(french)
print(soup.prettify(formatter="minimal"))
# <html>
#  <body>
#   <p>
#    Il a dit &lt;&lt;Sacrï¾ï½© bleu!&gt;&gt;
#   </p>
#  </body>
# </html>


ããã formatter="html" ãæ¸¡ãã°ãBSã¯ å¯è½ãªã¨ãã¯ãã¤ã§ããUnicodeæå­åã HTMLã¨ã³ãã£ãã£ã«å¤æãã¾ãã:
print(soup.prettify(formatter="html"))
# <html>
#  <body>
#   <p>
#    Il a dit &lt;&lt;Sacr&eacute; bleu!&gt;&gt;
#   </p>
#  </body>
# </html>


ããã formatter=None ãæ¸¡ãã°ãBSã¯åºåã«ããã¦ã¾ã£ããæå­åãä¿®æ­£ãã¾ããã
ããã¯ãæéã®ãªãã·ã§ã³ã§ãããBSãæ­£ãããªãHTML/XMLãçæãããã¨ã«ãªãã¾ãã
æ¬¡ã®ä¾ããè¦§ãã ããã:
print(soup.prettify(formatter=None))
# <html>
#  <body>
#   <p>
#    Il a dit <<Sacrï¾ï½© bleu!>>
#   </p>
#  </body>
# </html>

link_soup = BeautifulSoup('<a href="http://example.com/?foo=val1&bar=val2">A link</a>')
print(link_soup.a.encode(formatter=None))
# <a href="http://example.com/?foo=val1&bar=val2">A link</a>


formatter ã«é¢æ°ãæ¸¡ãã¨ããã­ã¥ã¡ã³ãã®æå­åãå±æ§å¤ã®ãã³ã«ãBSã¯ãã®é¢æ°ãã³ã¼ã«ãã¾ãã
é¢æ°åã§æããã¨ã¯ãªãã§ããã§ãã¾ãã
ä»¥ä¸ã§ã¯ãformatterã¯æå­åãå¤§æå­ã«ã³ã³ãã¼ãããä»ã«ã¯ä½ããã¾ããã:
def uppercase(str):
    return str.upper()

print(soup.prettify(formatter=uppercase))
# <html>
#  <body>
#   <p>
#    IL A DIT <<SACRï¾ BLEU!>>
#   </p>
#  </body>
# </html>

print(link_soup.a.prettify(formatter=uppercase))
# <a href="HTTP://EXAMPLE.COM/?FOO=VAL1&BAR=VAL2">
#  A LINK
# </a>


ããããªããããªãã®é¢æ°ãæ¸ãããªããããªãã¯ bs4.dammit ã®  EntitySubstitution ã¯ã©ã¹ã«ã¤ãã¦ç¥ãã¹ãã§ãã
ãã®ã¯ã©ã¹ã¯ãBSã®æ¨æºçãªformatter ãã¯ã©ã¹ã¡ã½ããã¨ãã¦ååãã¾ãã
“html” formatterã¯    EntitySubstitution.substitute_html ,
“minimal” formatterã¯ EntitySubstitution.substitute_xml ã§ãã
ããªãã¯ããããã®é¢æ°ãã formatter==html ã formatter==minimal ãã·ã¥ãã¬ã¼ã·ã§ã³ãã¾ãã
ããããããã«å ãã¦ä»ã®ãã¨ããã¾ãã
ããã¯ä¾ã§ããUnicodeã­ã£ã©ã¯ã¿ãHTMLã¨ã³ãã£ãã£ã«ç½®æãã¾ããå¯è½ãªã¨ãã¯ãã¤ã§ãã
ãããã ã¾ã å¨ã¦ã®æå­åãå¤§æå­ã«å¤æãã¾ãã:
from bs4.dammit import EntitySubstitution
def uppercase_and_substitute_html_entities(str):
    return EntitySubstitution.substitute_html(str.upper())

print(soup.prettify(formatter=uppercase_and_substitute_html_entities))
# <html>
#  <body>
#   <p>
#    IL A DIT &lt;&lt;SACR&Eacute; BLEU!&gt;&gt;
#   </p>
#  </body>
# </html>


æå¾ã«ä¸ç¹(æçµéå?): ãã CData ãªãã¸ã§ã¯ããçæããã¨ãã¯ããã®ãªãã¸ã§ã¯ãåã®ãã­ã¹ãã¯ æ­£ç¢ºã«ãããã¾ã¾ããã©ã¼ãããããããã¨ãªã ãã¤ãè¡¨ããã¾ãã
BSã¯ formatterã¡ã½ãããå¼åºãã¾ããããªããã«ã¹ã¿ã ã¡ã½ãããæ¸ããå ´åã«ã®ã¿ãã©ãããã«ã¹ã¿ã ã¡ã½ããåã¨ããã¨ãå¨ã¦ã®ãã­ã¥ã¡ã³ãåã®æå­åããªã«ããcountãããããããããã¯è¿ãå¤ãç¡è¦ãã¾ãã:
from bs4.element import CData
soup = BeautifulSoup("<a></a>")
soup.a.string = CData("one < three")
print(soup.a.prettify(formatter="xml"))
# <a>
#  <![CDATA[one < three]]>
# </a>




get_text()Â¶
ãã­ã¥ã¡ã³ããã¿ã°ã®ãã­ã¹ãé¨åã ããåå¾ãããã¨ãã¯ã get_text() ã¡ã½ãããä½¿ãã¾ãã
ããã¯ãå¨ãã­ã¥ã¡ã³ããä¸å±¤ã®ã¿ã°ããã¦ãã³ã¼ãã®åä¸æå­åã¨ãã¦è¿ãã¾ãã:
markup = '<a href="http://example.com/">\nI linked to <i>example.com</i>\n</a>'
soup = BeautifulSoup(markup)

soup.get_text()
u'\nI linked to example.com\n'
soup.i.get_text()
u'example.com'


ãã­ã¹ããã¾ã¨ããéã®åºåãæå­ãæå®ãããã¨ãã§ãã¾ãã:
# soup.get_text("|")
u'\nI linked to |example.com|\n'


åæå­åãã¼ãã®æåã¨æå¾ã®ç©ºç½ãé¤å»ãããã¨ãã§ãã¾ãã:
# soup.get_text("|", strip=True)
u'I linked to|example.com'


ç©ºç½ãé¤å»ããã®ã«ã stripped_strings ã¸ã§ãã¬ã¼ã¿ã¼ãä½¿ã£ã¦å¦çãããã¨ãã§ãã¾ãã:
[text for text in soup.stripped_strings]
# [u'I linked to', u'example.com']





ãã¼ãµã¼ã®æå®Â¶
ããè²´æ¹ãããã¤ãã®htmlããã¼ã¹ããããªããããªãã¯ã Beautiful Soup ã³ã³ã¹ãã©ã¯ã¿ã«ããã¼ã¯ã¢ããããã³ãã§ããã
ããã¯ãã¶ããã¾ãããã¾ãã
Beautiful Soupã¯ãã¼ãµã¼ãé¸ãã§ããã¼ã¿ããã¼ã¹ãã¾ãã
ããããã©ã®ãã¼ãµã¼ãä½¿ããããå¤æ´ããããã«ãã³ã³ã¹ãã©ã¯ã¿ã«æ¸¡ãããã¤ãã®å¼æ°ãããã¾ã
ï¼ã¤ç®ã® BeautifulSoup ã³ã³ã¹ãã©ã¯ã¿ã®å¼æ°ã¯ã ããªãããã¼ã¹ããããã¼ã¯ã¢ããã®ãæå­åã¾ãã¯éãã¦ãããã¡ã¤ã«ãã³ãã«ã§ãã
ï¼ã¤ç®ã®å¼æ°ã¯ãã©ã®ããã« ãã¼ã¯ã¢ãããã±ã¼ããããã«ã¤ãã¦ã§ãã
ããä½ãæå®ããªãã£ãå ´åã¯ãã¤ã³ã¹ãã¼ã«ããã¦ãããªãã§æé«ã®HTMLãã¼ãµã¼ãä½¿ãã¾ãã
Beautiful Soupã¯ãlxmlã®ãã¼ãµã¼ãæé«ã®ãã®ã¨ãã¦ãã¾ããããã¦ãhtml5libã¨Pythonã®çµã¿è¾¼ã¿ãã¼ãµã¼ã
ããªãã¯æ¬¡ã®ãã¡ã®ä¸ã¤ãæå®ãããã¨ã§ããããä¸æ¸ãã§ãã¾ãã

ãã¼ã¹ããããã¼ã¯ã¢ããã®ç¨®é¡: ãµãã¼ããã¦ããã®ã¯ã”html”, “xml”, “html5”ã§ãã


ãã¼ãµã¼ã©ã¤ãã©ãªã®åå: ãªãã·ã§ã³ã¨ãã¦ãµãã¼ããã¦ããã®ã¯ã”lxml”, “html5lib”, (Pythonã®çµã¿è¾¼ã¿HTMLãã¼ãµã¼ã§ãã) “html.parser”ã

ãã® ãã¼ãµã¼ã®ã¤ã³ã¹ãã¼ã« ã®ç« ã¯ããµãã¼ããã¦ãããã¼ãµã¼ãæ¯è¼ãã¾ãã
ããé©åãªãã¼ãµã¼ãã¤ã³ã¹ãã¼ã«ãã¦ããªãã¨ãã¯ãBeautiful Soupã¯ããªãã®ãªã¯ã¨ã¹ããç¡è¦ããéããã¼ãµã¼ãé¸ã³ã¾ãã
ç¾å¨ããã ä¸ã¤ãµãã¼ãããã¦ããXMLãã¼ãµã¼ã¯ãlxmlã§ãã
ãããlxmlãã¤ã³ã¹ãã¼ã«ãã¦ãªãã¨ããXMLã®è¦æ±ã¯ããªãã«ä½ãä¸ãã¾ãããã”lxml”ã¸ã®ãªã¯ã¨ã¹ããåãã¾ããã(è¦æ¹å!)

ãã¼ãµã¼ã®éãÂ¶
Beautiful Soupã¯å¤ãã®ç°ãªããã¼ãµã¼ã«åãã¤ã³ã¿ã¼ãã§ã¼ã¹ãæä¾ãã¦ãã¾ãã
ãããããã¼ãµã¼ã¯ããããã¯ç°ãªãã¾ãã
ãã¼ãµã¼ãç°ãªãã¨ãåããã­ã¥ã¡ã³ãã§ããçæããããã¼ã¹ããªã¼ã¯ç°ãªã£ã¦ãã¾ãã
HTMLãã¼ãµã¼ã¨XMLãã¼ãµã¼ã«ã¯å¤§ããªéããããã¾ãã
ä»¥ä¸ã¯ãç­ããã­ã¥ã¡ã³ããHTMLã¨ãã¦ãã¼ã¹ãããã®ã§ãã:
BeautifulSoup("<a><b /></a>")
# <html><head></head><body><a><b></b></a></body></html>


ç©ºã®<b />ã¿ã°ã¯ãæ­£å¼ãªHTMLã§ã¯ãªãããããã¼ãµã¼ã¯ããã<b></b>ã®ã¿ã°ã®çµã«å¤æãã¾ãã
ä»¥ä¸ã¯ãåããã­ã¥ã¡ã³ããXMLã¨ãã¦ãã¼ã¹ãããã®ã§ãã
(ãããå®è¡ããã«ã¯lxmlãã¤ã³ã¹ãã¼ã«ãã¦ããå¿è¦ãããã¾ã)
<b />ã¿ã°ã¯ãã®ã¾ã¾æ®ã£ã¦ããããã­ã¥ã¡ã³ãã¯XMLå®£è¨ã<html>ã¿ã°ã®ä»£ããã«å ãããããã¨ã«æ°ã¥ãã¦ãã ããã:
BeautifulSoup("<a><b /></a>", "xml")
# <?xml version="1.0" encoding="utf-8"?>
# <a><b/></a>


HTMLãã¼ãµã¼åå£«ã§ããéãã¯ããã¾ãã
å®å¨ãªå½¢ã®HTMLãã­ã¥ã¡ã³ããBeautiful Soupã«ä¸ããã¨ãã¯ããã®éãã¯åé¡ã«ãªãã¾ããã
ãããã¼ãµã¼ã¯ãä»ã®ãã¼ãµã¼ãããéãã§ãããã
ãããããããã¯å¨ã¦åã®HTMLãã­ã¥ã¡ã³ããæ­£ç¢ºã«åæ ãããã¼ã¿æ§é ãä¸ããã§ãããã
ããããä¸å®å¨ãªå½¢ã®HTMLãã­ã¥ã¡ã³ãã®ã¨ãã¯ãç°ãªããã¼ãµã¼ã¯ç°ãªãçµæãåºåãã¾ãã
ä»¥ä¸ã¯ãlxmlã®HTMLãã¼ãµã¼ã«ãã£ã¦ãã¼ã¹ãããç­ãä¸æ­£ãªãã­ã¥ã¡ã³ãã§ãã
ã¶ãããã£ã¦ãã</p>ã¿ã°ã¯ãåã«ç¡è¦ããã¦ãããã¨ã«æ°ã¥ãã¦ãã ããã:
BeautifulSoup("<a></p>", "lxml")
# <html><body><a></a></body></html>


ä»¥ä¸ã¯ãhtml5libã«ãã£ã¦ãã¼ã¹ãããåããã­ã¥ã¡ã³ãã§ãã:
BeautifulSoup("<a></p>", "html5lib")
# <html><head></head><body><a><p></p></a></body></html>


ã¶ãããã£ã¦ãã</p>ã¿ã°ãç¡è¦ããä»£ããã«ãhtml5libã¯ããããéå§ã®<p>ã¿ã°ã¨çµã«ãã¾ããã
ãã®ãã¼ãµã¼ã¯ã¾ãããã­ã¥ã¡ã³ãã«ç©ºã®<head>ã¿ã°ãå ãã¾ããã
ä»¥ä¸ã¯ãPythonçµã¿è¾¼ã¿ã®HTMLãã¼ãµã¼ã§åããã­ã¥ã¡ã³ãããã¼ã¹ãããã®ã§ãã:
BeautifulSoup("<a></p>", "html.parser")
# <a></a>


html5libã®ããã«ããã®ãã¼ãµã¼ã¯çµããã®</p>ã¿ã°ãç¡è¦ãã¾ãã
html5libã¨ã¯éãããã®ãã¼ãµã¼ã¯<body>ã¿ã°ãå ãã¦æ­£ããæ¸å¼ã®HTMLãã­ã¥ã¡ã³ããä½æãããã¨ã¯ãã¾ããã
lxmlã¨ã¯éãããªãã¨ããã¦<html>ã¿ã°ãå ãããã¨ã¯ãã¾ããã
“<a></p>”ã¨ãããã­ã¥ã¡ã³ãã¯ä¸æ­£ãªã®ã§ãããã«ã¤ãã¦ã®”æ­£ãã”å¦çæ¹æ³ã¯ããã¾ããã
html5libãã¼ãµã¼ã¯html5æ¨æºã®ãã¡é¨åã®ãã¯ããã¯ãä½¿ãã¾ãã
ããã¯ããã ããä¸»å¼µãæ­£ããæ¹æ³ã«ã¤ãã¦ãã¾ãããããããããã®3ã¤ã®æ¹æ³å¨ã¦ãéçã«åã£ã¦ãã¾ãã(?ãã¨ã§åãã§ãã¯)
ãã¼ãµã¼éã®éãã¯ãããªãã®ã¹ã¯ãªããã«ãå½±é¿ããã§ãããã
ãããã¹ã¯ãªãããä»ã®äººã«éå¸ããããè¤æ°ã®è¨ç®æ©ã§å®è¡ãããã¨ãããªãã°ã Beautiful Soup ã³ã³ã¹ãã©ã¯ã¿ã«ã¤ãã¦ãã¼ãµã¼ãæå®ããã¹ãã§ãã
ãããããã¨ã«ãã£ã¦ãããªãããã¼ã¹ããæ¹æ³ã¨éãããããã§ãã­ã¥ã¡ã³ãããã¼ã¹ããå¯è½æ§ãæ¸ããã§ãããã



ã¨ã³ã³ã¼ãÂ¶
HTMLãXMLãã­ã¥ã¡ã³ãã¯å¨ã¦ãASCIIãUTF-8ã®ãããªç¹å®ã®æå­ã³ã¼ãã§æ¸ããã¦ãã¾ãã
ããããBeautifulSoupã«ãã­ã¥ã¡ã³ããã­ã¼ãããã¨ããããã¯Unicodeåã«å¤æããã¾ãã:
markup = "<h1>Sacr\xc3\xa9 bleu!</h1>"
soup = BeautifulSoup(markup)
soup.h1
# <h1>SacrÃ© bleu!</h1>
soup.h1.string
# u'Sacr\xe9 bleu!'


ããã¯é­æ³ã§ã¯ããã¾ãããBeautiful Soupã¯ Unicode, Dammit ãåé¨ã§ã©ã¤ãã©ãªã¨ãã¦å¼ã³åºããæå­ã³ã¼ããå¤å¥ãã¦Unicodeã«å¤æããã®ã«ä½¿ã£ã¦ãã¾ãã
èªåå¤å¥ãããæå­ã³ã¼ãã¯ã BeautifulSoup ãªãã¸ã§ã¯ãã® .original_encoding å±æ§ã§åç§ãããã¨ãã§ãã¾ãã:
soup.original_encoding
'utf-8'


Unicode, Dammit ã¯ã»ã¨ãã©ã®å ´åæ­£ããå¤å¥ãã¾ããããã¾ã«å¤±æãã¾ãã
ããã¦ãé©åã«å¤å¥ãã¾ããããã¤ãæ¯ã®æ¤ç´¢ã®å ´åã¯ãã¨ã¦ããªããæéããããã¾ãã
ããããã­ã¥ã¡ã³ãã®æå­ã³ã¼ããåãã£ã¦ããã®ãªããå¤±æãéå»¶ãé¿ããããã«ã BeautifulSoup ã³ã³ã¹ãã©ã¯ã¿ã« from_encoding ã¨ãã¦æ¸¡ãã¨ããã§ãã
æ¬¡ã®ä¾ã¯ãISO-8859-8(è¨³æ³¨:ã©ãã³æå­ç­ã®æå­ã³ã¼ã)ã§æ¸ããããã­ã¥ã¡ã³ãã§ãã
ãã®ãã­ã¥ã¡ã³ãã¯ç­ãããã«ãUnicode, Dammitã¯ãããä½ãå¤å¥ã§ããããããISO-8859-7(è¨³æ³¨:ã®ãªã·ã¢æå­ç­ã®æå­ã³ã¼ã)ã¨èª¤èªãã¾ãã:
markup = b"<h1>\xed\xe5\xec\xf9</h1>"
soup = BeautifulSoup(markup)
soup.h1
<h1>Î½ÎµÎ¼Ï</h1>
soup.original_encoding
'ISO-8859-7'

æ­£ãã from_encoding ãæ¸¡ããã¨ã§ããããæ­£ããã¨ãã§ãã¾ãã:
soup = BeautifulSoup(markup, from_encoding="iso-8859-8")
soup.h1
<h1>× × × ×©</h1>
soup.original_encoding
'iso8859-8'

(éå¸¸ãUTF-8ã®ãã­ã¥ã¡ã³ãã¯è¤æ°ã®æå­ã³ã¼ããå«ããã¨ãã§ãã¾ããã) ããã¾ãã«ãå¤æã§ããªãæå­ãã¦ãã³ã¼ãã®ç¹æ®æå­”REPLACEMENT CHARACTER” (U+FFFD,ï¿½) ã«ç½®ãæãããã¨ãããã¾ãã
Unicode, Dammit ããããè¡ãã¨ãã¯ãåæã«ã UnicodeDammit ã BeautifulSoup ãªãã¸ã§ã¯ãã® .contains_replacement_characters å±æ§ã«Trueãã»ãããã¾ãã
ããã«ãããå¤æå¾ã®ã¦ãã³ã¼ãã®æå­åã¯ãåã®æå­ã³ã¼ãã®æå­åãæ­£ç¢ºã«è¡¨ç¾ãã¦ããããããã¤ãã®ãã¼ã¿ãæãªããã¦ããã¨ãããã¨ããããã¾ãã
ããã .contains_replacement_characters ã False ã®ã¨ãã¯ããã­ã¥ã¡ã³ãåã«ç¹æ®æå­ï¿½ããã£ã¦ããããã¯(ãã®æ®µè½ã®ï¿½ã®ããã«)ãã¨ãã¨ããããã¼ã¿ã¯æãªããã¦ããªãã¨ãããã¨ã§ãã

åºåã®ã¨ã³ã³ã¼ãÂ¶
Beautiful Soupã§ãã­ã¥ã¡ã³ããåºåããã¨ãåã®ãã­ã¥ã¡ã³ããUTF-8ã§ãªãã¦ããUTF-8ã§åºåããã¾ãã
æ¬¡ã®ä¾ã¯ãLatin-1ã§æ¸ããããã­ã¥ã¡ã³ãã«ã¤ãã¦ã§ãã:
markup = b'''
 <html>
  <head>
   <meta content="text/html; charset=ISO-Latin-1" http-equiv="Content-type" />
  </head>
  <body>
   <p>Sacr\xe9 bleu!</p>
  </body>
 </html>
'''

soup = BeautifulSoup(markup)
print(soup.prettify())
# <html>
#  <head>
#   <meta content="text/html; charset=utf-8" http-equiv="Content-type" />
#  </head>
#  <body>
#   <p>
#    Sacrï¾ï½© bleu!
#   </p>
#  </body>
# </html>


<meta>ã¿ã°ã¯æ¸ãæãããããã­ã¥ã¡ã³ããç¾å¨UTF-8ã§ãããã¨ãç¤ºãã¦ãã¾ãã:
.. If you don't want UTF-8, you can pass an encoding into ``prettify()``::

UTF-8ä»¥å¤ã§åºåãããã¨ãã¯ã prettify() ã«ãã®æå­ã³ã¼ããæ¸¡ãã¦ãã ããã:
print(soup.prettify("latin-1"))
# <html>
#  <head>
#   <meta content="text/html; charset=latin-1" http-equiv="Content-type" />
# ...


Pythonã®stråã§ãããã®ããã«ãBeautifulSoup ãªãã¸ã§ã¯ããããã®è¦ç´ ã®encode()ãã³ã¼ã«ãããã¨ãã§ãã¾ãã:
soup.p.encode("latin-1")
# '<p>Sacr\xe9 bleu!</p>'

soup.p.encode("utf-8")
# '<p>Sacr\xc3\xa9 bleu!</p>'


ããªããé¸ãã æå­ã³ã¼ãã§ã¯è¡¨ããªãæå­ã¯ãXMLã¨ã³ãã£ãã£ãªãã¡ã¬ã³ã¹ã®æ°å­ã«å¤æããã¾ãã
æ¬¡ã®ä¾ã¯ãã¹ãã¼ãã³ã®ã¦ãã³ã¼ãæå­ãå«ãã ãã­ã¥ã¡ã³ãã§ãã:
markup = u"<b>\N{SNOWMAN}</b>"
snowman_soup = BeautifulSoup(markup)
tag = snowman_soup.b


ã¹ãã¼ãã³ã®æå­ã¯UTF-8ã®ãã­ã¥ã¡ã³ãã«çµã¿è¾¼ãã¾ãã(ããã¯âã¨è¡¨ç¤ºããã¾ããããããISO-Latin-1ãASCIIã«ã¯ãã®æå­ãããã¾ãããããã§ããããã®æå­ã³ã¼ãã§ã¯”&#9731”ã«å¤æããã¾ãã):
print(tag.encode("utf-8"))
# <b>â</b>

print tag.encode("latin-1")
# <b>&#9731;</b>

print tag.encode("ascii")
# <b>&#9731;</b>




Unicode, DammitÂ¶
Beautiful Soup æãã§ãUnicode, Dammitãä½¿ãã¾ãã
æå­ã³ã¼ããããããªããã¼ã¿ãæã¤ã¨ãããUnicodeã«ãã®ãã¼ã¿ãå¤æãããã¨ãã¯ãããã¯ä¾¿å©ã§ãã:
from bs4 import UnicodeDammit
dammit = UnicodeDammit("Sacr\xc3\xa9 bleu!")
print(dammit.unicode_markup)
# SacrÃ© bleu!
dammit.original_encoding
# 'utf-8'


Pythonã©ã¤ãã©ãª chardet ã cchardet ãã¤ã³ã¹ãã¼ã«ãã¦ããã°ãUnicode, Dammitã¯ããã«æ­£ç¢ºã«æå­ã³ã¼ããæ¨æ¸¬ã§ãã¾ãã:
dammit = UnicodeDammit("Sacr\xe9 bleu!", ["latin-1", "iso-8859-1"])
print(dammit.unicode_markup)
# SacrÃ© bleu!
dammit.original_encoding
# 'latin-1'


Unicode, Dammitã«ã¯ãBeautiful Soupãä½¿ããªã2ã¤ã®æ©è½ãããã¾ãã

ã¹ãã¼ãå¼ç¨ç¬¦Â¶
(è¨³æ³¨: ã¹ãã¼ãå¼ç¨ç¬¦ã¨ã¯ãå¼ç¨ç¬¦’ã§å·¦å³ã®åã(open/close)ãåºå¥ããã¦ãããã®ã®ãã¨ã§ãã
ASCIIã³ã¼ããã·ããJISã®å¼ç¨ç¬¦ã¯åºå¥ããã¦ãã¾ããã
[ åèãªã³ã¯ ])
Unicode, Dammitã¯ Microsoftã¹ãã¼ãå¼ç¨ç¬¦ããHTMLãXMLã®ã¨ã³ãã£ãã£ã«å¤æãã¾ãã:
markup = b"<p>I just \x93love\x94 Microsoft Word\x92s smart quotes</p>"

UnicodeDammit(markup, ["windows-1252"], smart_quotes_to="html").unicode_markup
# u'<p>I just &ldquo;love&rdquo; Microsoft Word&rsquo;s smart quotes</p>'

UnicodeDammit(markup, ["windows-1252"], smart_quotes_to="xml").unicode_markup
# u'<p>I just &#x201C;love&#x201D; Microsoft Word&#x2019;s smart quotes</p>'


Microsoftã¹ãã¼ãå¼ç¨ç¬¦ãASCIIå¼ç¨ç¬¦ã«å¤æã§ãã¾ãã:
UnicodeDammit(markup, ["windows-1252"], smart_quotes_to="ascii").unicode_markup
# u'<p>I just "love" Microsoft Word\'s smart quotes</p>'


ã§ããã°ãã®æ©è½ãä¾¿å©ã«ä½¿ã£ã¦ã»ããã§ãããBeautiful Soupã¯ãããä½¿ãã¾ããã
Beautiful Soupã¯ãä»ã®æå­ã¨åãããã«ãMicrosoftã¹ãã¼ãå¼ç¨ç¬¦ãUnicodeã­ã£ã©ã¯ã¿ã«å¤æããã¨ãããããã©ã«ãã®æ¯ãã¾ããé¸ã³ã¾ãã:
UnicodeDammit(markup, ["windows-1252"]).unicode_markup
# u'<p>I just \u201clove\u201d Microsoft Word\u2019s smart quotes</p>'




è¤æ°ã®æå­ã³ã¼ãÂ¶
ã¨ãã©ããã»ã¼UTF-8ã§æ¸ããã¦ããããä¸é¨Microsoftã¹ãã¼ãå¼ç¨ç¬¦ã®ãããªæå­ã³ã¼ããWindows-1252ã®æå­ãå«ããã­ã¥ã¡ã³ããããã¾ãã:
snowmen = (u"\N{SNOWMAN}" * 3)
quote = (u"\N{LEFT DOUBLE QUOTATION MARK}I like snowmen!\N{RIGHT DOUBLE QUOTATION MARK}")
doc = snowmen.encode("utf8") + quote.encode("windows_1252")


ãã®ãã­ã¥ã¡ã³ãã¯æ±ãã«å°ãã¾ãã
ã¹ãã¼ãã³ã¯UTF-8ã§ãããã¹ãã¼ãå¼ç¨ç¬¦ã¯Windows-1252ã§ãã
ã¹ãã¼ãã³ãå¼ç¨ç¬¦ã®ã©ã¡ããããè¡¨ç¤ºã§ãã¾ããã:
print(doc)
# âââï¿½I like snowmen!ï¿½

print(doc.decode("windows-1252"))
# Ã¢ËÆÃ¢ËÆÃ¢ËÆâI like snowmen!â


ãã­ã¥ã¡ã³ããUTF-8ã¨ãã¦ãã³ã¼ãããã¨ã UnicodeDecodeError ãçºçããWindows-1252ã§ãã³ã¼ãããã¨æå³ä¸æ(gibberish?)ãªãã¨ã«ãªãã¾ãã
å¹¸ããªãã¨ã«ã UnicodeDammit.detwingle() ã¯ãã®æå­ãpure UTF-8ã«å¤æãããããUnicodeã«ãã³ã¼ãããã¹ãã¼ãã³ã¨å¼ç¨ç¬¦ãä¸¦ã¹ã¦è¡¨ç¤ºãããã¨ãè¨±å¯ãã¾ãã:
new_doc = UnicodeDammit.detwingle(doc)
print(new_doc.decode("utf8"))
# ââââI like snowmen!â


UnicodeDammit.detwingle() UTF-8ã«åãè¾¼ã¾ããWindows-1252ã®æå­ãæ±ãæ¹æ³(ã¨ãã®é)ã®ã¿ãç¥ã£ã¦ãã¾ãããããããã¯ãããããã±ã¼ã¹ã§ã¯ããã¾ããã
ãã¼ã¿ã BeautifulSoup ã UnicodeDammit ã³ã³ã¹ãã©ã¯ã¿ã«æ¸¡ãåã«ã UnicodeDammit.detwingle() ãã³ã¼ã«ããªããã°ãªããªããã¨ã«æ³¨æãã¦ãã ããã
Beautiful Soupã¯ ä½ããã®åä¸ã®æå­ã³ã¼ãã§ãã­ã¥ã¡ã³ããè¨ããã¦ããã¨æ³å®ãã¦ãã¾ãã
ãããUTF-8ã¨Windows-1252ã®ä¸¡æ¹ãå«ããã­ã¥ã¡ã³ããæ¸¡ãããããã­ã¥ã¡ã³ãå¨ä½ãWindows-1252ã¨å¤æ­ããã¡ã§ããããã¦ãããã¦ãã®ãã­ã¥ã¡ã³ãã®åºåã¯ã ` ï¾ï½¢ï¾æ´æ´¥ï½¢ï¾æ´æ´¥ï½¢ï¾æ´åå»¬ like snowmen!çª¶æ` ã®ããã«ãªãã¾ãã
UnicodeDammit.detwingle() ã¯Beautiful Soup 4.1.0ããã®æ©è½ã§ãã




ãã­ã¥ã¡ã³ãã®ä¸é¨ããã¼ã¹Â¶
ãããã­ã¥ã¡ã³ãã®<a>ã¿ã°ã«å¯¾ãã¦Beautiful Soupãä½¿ãããå ´åããã­ã¥ã¡ã³ãå¨é¨ããã¼ã¹ãã¦ããã®ä¸­ãã<a>ã¿ã°ãæ¢ãã®ã¯ãæéã¨ã¡ã¢ãªã®ç¡é§ã§ãã
æåã«ã§ã¦ãã<a>ã¿ã°ä»¥å¤ãå¨ã¦ç¡è¦ããã°ãå¦çã¯éããªãã¾ãã
SoupStrainer ã¯ã©ã¹ã¯ãä¸ãããããã­ã¥ã¡ã³ãã®ã©ã®é¨åããã¼ã¹ããããé¸ã¶ãã¨ãã§ãã¾ãã
ãã®ããã«ã¯ã SoupStrainer ãä½æããããã BeautifulSoup ã³ã³ã¹ãã©ã¯ã¿ã« parse_only å±æ§ã¨ãã¦æ¸¡ãã ãã§ãã
(ãã®æ©è½ã¯html5libãã¼ãµã¼ãä½¿ã£ã¦ããã¨ãã¯ãä½¿ããªããã¨ã«ãæ³¨æãã ããã
ããhtml5libãä½¿ãã¨ãã¯ã©ããªã¨ãã§ãããã­ã¥ã¡ã³ãå¨ä½ããã¼ã¹ããã¾ãã
ããã¯ãhtml5libããã¼ã¹ããªã¼ããã®ããã«ç¶ç¶çã«åæ§ç¯ããããã§ãã
ããããã­ã¥ã¡ã³ãã®ä¸é¨ããã¼ã¹ããªã¼ã«çµã¿è¾¼ã¾ãã¦ãªãå ´åã¯ãããã¯è£ãã·ã¥ãã¾ãã
ããããããããã«ã¯ãä¾ã«ããã¦ãBeautiful SoupãPythonã®çµã¿è¾¼ã¿ãã¼ãµã¼ãå©ç¨ããã¦ãã ãã)

SoupStrainerÂ¶
SoupStrainer (ã¹ã¼ãæ¼ãå¨)ã¯ã©ã¹ã¯ã ãã¼ã¹ããªã¼ãæ¤ç´¢: ããã¨ãã®å¸åçãªã¡ã½ããã§ãã name, attrs, text, and **kwargs ããã¡ã¾ãã
ä»¥ä¸ã¯ã SoupStrainer ãªãã¸ã§ã¯ãã®3éãã®ä¾ã§ãã:
from bs4 import SoupStrainer

only_a_tags = SoupStrainer("a")

only_tags_with_id_link2 = SoupStrainer(id="link2")

def is_short_string(string):
    return len(string) < 10

only_short_strings = SoupStrainer(text=is_short_string)


ããã§ã”three sisters”ãã­ã¥ã¡ã³ããããä¸åã¨ãããã¾ãã
ãã­ã¥ã¡ã³ãã SoupStrainer ãªãã¸ã§ã¯ãã§3éãã«ãã¼ã¹ããã®ã§ãã©ããªãããè¦ã¦ã¿ã¾ãããã:
html_doc = """
<html><head><title>The Dormouse's story</title></head>

<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""

print(BeautifulSoup(html_doc, "html.parser", parse_only=only_a_tags).prettify())
# <a class="sister" href="http://example.com/elsie" id="link1">
#  Elsie
# </a>
# <a class="sister" href="http://example.com/lacie" id="link2">
#  Lacie
# </a>
# <a class="sister" href="http://example.com/tillie" id="link3">
#  Tillie
# </a>

print(BeautifulSoup(html_doc, "html.parser", parse_only=only_tags_with_id_link2).prettify())
# <a class="sister" href="http://example.com/lacie" id="link2">
#  Lacie
# </a>

print(BeautifulSoup(html_doc, "html.parser", parse_only=only_short_strings).prettify())
# Elsie
# ,
# Lacie
# and
# Tillie
# ...
#


SoupStrainer ãã¼ã¹ããªã¼ãæ¤ç´¢ ã®ã¡ã½ããã«æ¸¡ããã¨ãã§ãã¾ãã
ããã¯ãã¨ã¦ãä¾¿å©ã§ããå°ãã ãèª¬æãã¾ãã:
soup = BeautifulSoup(html_doc)
soup.find_all(only_short_strings)
# [u'\n\n', u'\n\n', u'Elsie', u',\n', u'Lacie', u' and\n', u'Tillie',
#  u'\n\n', u'...', u'\n']





ãã©ãã«ã·ã¥ã¼ãã£ã³ã°Â¶

diagnose()Â¶
ãããBeautiful Soupããã­ã¥ã¡ã³ãã«ä½ãããã¦ãã©ãã«ã«ãªã£ã¦ããã¨ãã¯ãã©ã®ãã­ã¥ã¡ã³ãã diagnose() é¢æ°ã«æ¸¡ãã¦ã¿ã¦ãã ããã(ããã¯Beautiful Soup 4.2.0ã®æ°æ©è½ã§ã)
Beautiful Soupã¯ãã©ã®ããã«ãã¼ãµã¼ããã®ãã­ã¥ã¡ã³ããæ±ã£ããã¨ããã¬ãã¼ããåºåããBeautifulSoupãä½¿ã£ã¦ãããã¼ãµã¼ãå¤±ã£ã¦ãããã©ãããæãã¦ããã¾ãã:
from bs4.diagnose import diagnose
data = open("bad.html").read()
diagnose(data)

# Diagnostic running on Beautiful Soup 4.2.0
# Python version 2.7.3 (default, Aug  1 2012, 05:16:07)
# I noticed that html5lib is not installed. Installing it may help.
# Found lxml version 2.3.2.0
#
# Trying to parse your data with html.parser
# Here's what html.parser did with the document:
# ...


diagnose()ã®åºåãã¿ã¦ã¿ãã¨ãã©ã®ããã«åé¡ãè§£æ±ºããã°ããããããã§ãããããããããããªãã¦ããå©ãããã¨ããã¨ãã«ã diagnose() ã®åºåãè²¼ãä»ãããã¨ãã§ãã¾ãã


ãã¼ã¹æã«åºãã¨ã©ã¼Â¶
ãã¼ã¹ã¨ã©ã¼ã«ã¯2ç¨®é¡ããã¾ãã
1ã¤ã¯ãã¯ã©ãã·ã¥ã§ããBeautifuls Soupã«ãã­ã¥ã¡ã³ããèª­ã¿è¾¼ã¾ããã¨ãã«ãä¾å¤ãçºçãã¾ããããã¦ãããã¯ HTMLParser.HTMPParserError ã§ãã
ãã1ã¤ã¯ãæ³å®å¤ã®åä½ã§ããBeautiful Soupã®ãã¼ã¹ããªã¼ããåã®ãã­ã¥ã¡ã³ãã®ãã¼ã¹ããªã¼ã¨ããªãéããã¨ãããã¾ãã
ãããã®ã¨ã©ã¼ã¯ãããã¦ãBeautiful Soupãåå ã§ã¯ããã¾ããããã®ããã«è¨ããã®ã¯ãBeautiful Soupãããã§ããã½ããã¦ã§ã¢ã ããã§ã¯ãªããBeautiful Soupããã¼ã¹å¦çã®ã³ã¼ããå«ãã§ããªãããã§ãã
ä»£ããã«ãBeautiful Soupã¯å¤é¨ã®ãã¼ãµã¼ã«é ¼ã£ã¦ãã¾ãããããããã¼ãµã¼ãæ­£ãããã­ã¥ã¡ã³ãããã¼ã¹ã§ããªãã¨ãã¯ãä»ã®ãã¼ãµã¼ãè©¦ãã¦ã¿ãã¨ããã®ãä¸çªè¯ãå¯¾å¦ã§ãã
ãã¼ãµã¼ã®ã¤ã³ã¹ãã¼ã« ã«ãããã«ã¤ãã¦ã®è©³ç´°ã¨ãã¼ãµã¼ã®æ¯è¼ãè¼ã£ã¦ãã¾ãã
ä¸çªããã¿ããã¼ã¹ã¨ã©ã¼ã¯ã HTMLParser.HTMLParseError: malformed start tag ã¨
HTMLParser.HTMLPraseError: bad end tag ã§ãããã
ãããã¯ã¨ãã«ãPythonçµã¿è¾¼ã¿ã®HTMLãã¼ãµã¼ã©ã¤ãã©ãªãè¿ãã¾ãã
ãã®å ´åã¯ã lxml ã html5lib ãã¤ã³ã¹ãã¼ã« ããã¨ããã§ãã
æ³å®å¤ã®åä½ã®ã¨ã©ã¼ã§æãå¤ãã®ã¯ãããã¨æã£ã¦ããã¿ã°ãè¦ã¤ããããªãã¨ãã§ãã
è¦ããã¨ããã¨æãã¾ããããã®ã¨ã find_all() ã¯ [] ãè¿ãã find() ã¯ None ãè¿ãã¾ãã
ããããPythonçµã¿è¾¼ã¿HTMLãã¼ãµã¼ã«ã¨ã£ã¦ã¯ãããããåé¡ã§ãããã¯ããä¸çªããå¯¾å¦ã¯ã lxml ã html5lib ãã¤ã³ã¹ãã¼ã« ãããã¨ã§ãã


ãã¼ã¸ã§ã³éãã®åé¡Â¶

SyntaxError: Invalid syntax (on the line ROOT_TAG_NAME =
u'[document]'): Python 2ãã¼ã¸ã§ã³ã®Beautiful Soupããå¤æããªãã§Python 3ã§å®è¡ããããã§ãã


ImportError: No module named HTMLParser - Python 2ãã¼ã¸ã§ã³ã®Beautiful SoupããPython 3ã§å®è¡ããããã§ãã


ImportError: No module named html.parser - Python 3ãã¼ã¸ã§ã³ã®Beautiful SoupããPython 2ã§å®è¡ããããã§ãã


ImportError: No module named BeautifulSoup - Beautiful Soup 3ã®ã³ã¼ãããBS3ãã¤ã³ã¹ãã¼ã«ããã¦ãªãç°å¢ã§å®è¡ãããããã¾ãã¯Beautiful Soup 4ã®ã³ã¼ããããã±ã¼ã¸åã bs4 ã«å¤ããã«å®è¡ããããã§ãã


ImportError: No module named bs4 - Beautiful Soup 4ã®ã³ã¼ãããBS4ãã¤ã³ã¹ãã¼ã«ããã¦ãªãç°å¢ã§å®è¡ããããã§ãã



XMLã®ãã¼ã¹Â¶
ããã©ã«ãã§ã¯ãBeautiful Soupã¯ãã­ã¥ã¡ã³ããHTMLã¨ãã¦ãã¼ã¹ãã¾ããXMLã¨ãã¦ãã¼ã¹ããã«ã¯ã BeautifulSoup ã³ã³ã¹ãã©ã¯ã¿ã®ç¬¬äºå¼æ°ã«ã “xml” ãæ¸¡ãã¾ãã:
soup = BeautifulSoup(markup, "xml")


ãã®ããã«ã¯ã lxml ãã¤ã³ã¹ãã¼ã« ãã¦ããå¿è¦ãããã¾ãã


ãã®ä»ã®ãã¼ãµã¼ã®åé¡Â¶

If your script works on one computer but not another, it’s probably
because the two computers have different parser libraries
available. For example, you may have developed the script on a
computer that has lxml installed, and then tried to run it on a
computer that only has html5lib installed. See ãã¼ãµã¼ã®éã
for why this matters, and fix the problem by mentioning a
specific parser library in the BeautifulSoup constructor.
Because HTML tags and attributes are case-insensitive, all three HTML
parsers convert tag and attribute names to lowercase. That is, the
markup <TAG></TAG> is converted to <tag></tag>. If you want to
preserve mixed-case or uppercase tags and attributes, you’ll need to
parse the document as XML.



ãã®ä»Â¶

UnicodeEncodeError: 'charmap' codec can't encode character
u'\xfoo' in position bar (or just about any other
UnicodeEncodeError) - This is not a problem with Beautiful Soup.
This problem shows up in two main situations. First, when you try to
print a Unicode character that your console doesn’t know how to
display. (See this page on the Python wiki for help.) Second, when
you’re writing to a file and you pass in a Unicode character that’s
not supported by your default encoding.  In this case, the simplest
solution is to explicitly encode the Unicode string into UTF-8 with
u.encode("utf8").
KeyError: [attr] - Caused by accessing tag['attr'] when the
tag in question doesn’t define the attr attribute. The most
common errors are KeyError: 'href' and KeyError:
'class'. Use tag.get('attr') if you’re not sure attr is
defined, just as you would with a Python dictionary.
AttributeError: 'ResultSet' object has no attribute 'foo' - This
usually happens because you expected find_all() to return a
single tag or string. But find_all() returns a _list_ of tags
and strings–a ResultSet object. You need to iterate over the
list and look at the .foo of each one. Or, if you really only
want one result, you need to use find() instead of
find_all().
AttributeError: 'NoneType' object has no attribute 'foo' - This
usually happens because you called find() and then tried to
access the .foo` attribute of the result. But in your case,
find() didn’t find anything, so it returned None, instead of
returning a tag or a string. You need to figure out why your
find() call isn’t returning anything.



ããã©ã¼ãã³ã¹æ¹åÂ¶
Beautiful Soup will never be as fast as the parsers it sits on top
of. If response time is critical, if you’re paying for computer time
by the hour, or if there’s any other reason why computer time is more
valuable than programmer time, you should forget about Beautiful Soup
and work directly atop lxml.
That said, there are things you can do to speed up Beautiful Soup. If
you’re not using lxml as the underlying parser, my advice is to
start. Beautiful Soup parses documents
significantly faster using lxml than using html.parser or html5lib.
You can speed up encoding detection significantly by installing the
cchardet library.
ãã­ã¥ã¡ã³ãã®ä¸é¨ããã¼ã¹ won’t save you much time parsing
the document, but it can save a lot of memory, and it’ll make
searching the document much faster.



Beautiful Soup 3Â¶
Beautiful Soup 3ã¯ä¸ã¤åã®ãªãªã¼ã¹ã§ããã§ã«éçºã¯åæ­¢ãã¦ãã¾ãã
ç¾å¨ã§ããå¨ã¦ã®ä¸»ãªLinuxãã£ã¹ããªãã¥ã¼ã·ã§ã³ã«å«ã¾ãã¦ãã¾ãã:
$ apt-get install python-beautifulsoup
Pypiã§ã BeautifulSoup ã¨ãã¦å©ç¨ã§ãã¾ãã
$ easy_install BeautifulSoup
$ pip install BeautifulSoup
æ¬¡ã®ãªã³ã¯ãããã¦ã³ã­ã¼ãã§ãã¾ããtarball of Beautiful Soup 3.2.0.
easy_install beautifulsoup , easy_install BeautifulSoup ã¨ããã³ãã³ãã§Beautiful Soupãã¤ã³ã¹ãã¼ã«ããã¨ãããªãã®ã³ã¼ãã¯åãã¾ããã easy_install beautifulsoup4 ã¨å¥åãã¾ãããã
Beautiful Soup 3 ã®ãã­ã¥ã¡ã³ãã¯ã¢ã¼ã«ã¤ãããã¦ãã¾ãã
æ¥æ¬èªçã¯æ¬¡ã®ãªã³ã¯ããåç§ã§ãã¾ãã Beautiful Soup ãã­ã¥ã¡ã³ã
Beautiful Soup 4ã§ã®å¤æ´ç¹ãçè§£ããããã«ããããã®ãã­ã¥ã¡ã³ããèª­ãã§ã¿ã¦ãã ããã

BS4ã¸ã®ç§»è¡Â¶
å¤ãã®BS3ã§æ¸ãããã³ã¼ãã¯ãä¸ãæå¤æ´ããã ãã§BS4ã§åãã¾ããããã±ã¼ã¸åã BeautifulSoup ãã bs4 ã«å¤æ´ããã ãã§ããããããã:
from BeautifulSoup import BeautifulSoup


ä»¥ä¸ã®ããã«ãã¾ãã:
from bs4 import BeautifulSoup



ImportError “No module named BeautifulSoup” ãè¡¨ç¤ºãããå ´åãBS4ããã¤ã³ã¹ãã¼ã«ããã¦ããªãã®ã«ãBS3ã®ã³ã¼ããå®è¡ãããã¨ããã®ãåé¡ã§ãã


ImportError “No module named bs4” ãè¡¨ç¤ºãããå ´åãBS3ããã¤ã³ã¹ãã¼ã«ããã¦ããªãã®ã«ãBS4ã®ã³ã¼ããå®è¡ãããã¨ããã®ãåé¡ã§ãã

BS4ã¯BS3ã®å¤§é¨åã«ã¤ãã¦å¾æ¹äºææ§ãããã¾ããããããã®ã¡ã½ããã®ã»ã¨ãã©ã¯å¤æ´ãã`PEP 8 è¦ç´ <http://www.python.org/dev/peps/pep-0008/>`_ ã«æ²¿ã£ãæ°ããååã«ãªã£ã¦ãã¾ããå¤ãã®ååç­ã®å¤æ´ã«ãããå¾æ¹äºææ§ã®ä¸é¨ãæãªããã¦ãã¾ãã
ä»¥ä¸ã¯ãBS3ã®ã³ã¼ããBS4ã«å¤æããã®ã«ç¥ã£ã¦ããã¹ãäºé ã§ãã:

ãã¼ãµã¼Â¶
Beautiful Soup 3 used Python’s SGMLParser, a module that was
deprecated and removed in Python 3.0. Beautiful Soup 4 uses
html.parser by default, but you can plug in lxml or html5lib and
use that instead. See ãã¼ãµã¼ã®ã¤ã³ã¹ãã¼ã« for a comparison.
Since html.parser is not the same parser as SGMLParser, it
will treat invalid markup differently. Usually the “difference” is
that html.parser crashes. In that case, you’ll need to install
another parser. But sometimes html.parser just creates a different
parse tree than SGMLParser would. If this happens, you may need to
update your BS3 scraping code to deal with the new tree.


ã¡ã½ããåÂ¶

renderContents -> encode_contents
replaceWith -> replace_with
replaceWithChildren -> unwrap
findAll -> find_all
findAllNext -> find_all_next
findAllPrevious -> find_all_previous
findNext -> find_next
findNextSibling -> find_next_sibling
findNextSiblings -> find_next_siblings
findParent -> find_parent
findParents -> find_parents
findPrevious -> find_previous
findPreviousSibling -> find_previous_sibling
findPreviousSiblings -> find_previous_siblings
nextSibling -> next_sibling
previousSibling -> previous_sibling

Some arguments to the Beautiful Soup constructor were renamed for the
same reasons:

BeautifulSoup(parseOnlyThese=...) -> BeautifulSoup(parse_only=...)
BeautifulSoup(fromEncoding=...) -> BeautifulSoup(from_encoding=...)

I renamed one method for compatibility with Python 3:

Tag.has_key() -> Tag.has_attr()

I renamed one attribute to use more accurate terminology:

Tag.isSelfClosing -> Tag.is_empty_element

I renamed three attributes to avoid using words that have special
meaning to Python. Unlike the others, these changes are not backwards
compatible. If you used these attributes in BS3, your code will break
on BS4 until you change them.

UnicodeDammit.unicode -> UnicodeDammit.unicode_markup
Tag.next -> Tag.next_element
Tag.previous -> Tag.previous_element



ã¸ã§ãã¬ã¼ã¿ã¼Â¶
I gave the generators PEP 8-compliant names, and transformed them into
properties:

childGenerator() -> children
nextGenerator() -> next_elements
nextSiblingGenerator() -> next_siblings
previousGenerator() -> previous_elements
previousSiblingGenerator() -> previous_siblings
recursiveChildGenerator() -> descendants
parentGenerator() -> parents

So instead of this:
for parent in tag.parentGenerator():
    ...


You can write this:
for parent in tag.parents:
    ...


(But the old code will still work.)
Some of the generators used to yield None after they were done, and
then stop. That was a bug. Now the generators just stop.
There are two new generators, .strings and
.stripped_strings. .strings yields
NavigableString objects, and .stripped_strings yields Python
strings that have had whitespace stripped.


XMLÂ¶
There is no longer a BeautifulStoneSoup class for parsing XML. To
parse XML you pass in “xml” as the second argument to the
BeautifulSoup constructor. For the same reason, the
BeautifulSoup constructor no longer recognizes the isHTML
argument.
Beautiful Soup’s handling of empty-element XML tags has been
improved. Previously when you parsed XML you had to explicitly say
which tags were considered empty-element tags. The selfClosingTags
argument to the constructor is no longer recognized. Instead,
Beautiful Soup considers any empty tag to be an empty-element tag. If
you add a child to an empty-element tag, it stops being an
empty-element tag.


ã¨ã³ãã£ãã£Â¶
An incoming HTML or XML entity is always converted into the
corresponding Unicode character. Beautiful Soup 3 had a number of
overlapping ways of dealing with entities, which have been
removed. The BeautifulSoup constructor no longer recognizes the
smartQuotesTo or convertEntities arguments. (Unicode,
Dammit still has smart_quotes_to, but its default is now to turn
smart quotes into Unicode.) The constants HTML_ENTITIES,
XML_ENTITIES, and XHTML_ENTITIES have been removed, since they
configure a feature (transforming some but not all entities into
Unicode characters) that no longer exists.
If you want to turn Unicode characters back into HTML entities on
output, rather than turning them into UTF-8 characters, you need to
use an output formatter.


ãã®ä»Â¶
Tag.string now operates recursively. If tag A
contains a single tag B and nothing else, then A.string is the same as
B.string. (Previously, it was None.)
å¤ãè¤æ°ã®ã¨ã like class have lists of strings as
their values, not strings. This may affect the way you search by CSS
class.
If you pass one of the find* methods both text and
a tag-specific argument like name, Beautiful Soup will
search for tags that match your tag-specific criteria and whose
Tag.string matches your value for text. It will not find the strings themselves. Previously,
Beautiful Soup ignored the tag-specific arguments and looked for
strings.
The BeautifulSoup constructor no longer recognizes the
markupMassage argument. It’s now the parser’s responsibility to
handle markup correctly.
The rarely-used alternate parser classes like
ICantBelieveItsBeautifulSoup and BeautifulSOAP have been
removed. It’s now the parser’s decision how to handle ambiguous
markup.
The prettify() method now returns a Unicode string, not a bytestring.








Table Of Contents

Beautiful Soup
(è¨³æ³¨)ç³é¹¸ã¯é£ã¹ãããªã
ãã®ææ¸ã«ã¤ãã¦
å©ãã¦ã»ããã¨ãã¯


ã¯ã¤ãã¯ã¹ã¿ã¼ã
ã¤ã³ã¹ãã¼ã«
ã¤ã³ã¹ãã¼ã«å¾ã®åé¡
ãã¼ãµã¼ã®ã¤ã³ã¹ãã¼ã«


ã¹ã¼ãã®ä½æ
4ç¨®é¡ã®ãªãã¸ã§ã¯ã
Tag obj.
åå
å±æ§
å¤ãè¤æ°ã®ã¨ã




NavigableString obj.
BeautifulSoup obj.
Comments obj. ä»


ãã¼ã¹ããªã¼ãæ¢ç´¢
å­è¦ç´ ã¸ä¸ç§»å
ã¿ã°åã§æ¢ç´¢
.contents / .children
.descendants
.string
.strings / .stripped_strings


è¦ªè¦ç´ ã¸ä¸ç§»å
.parent
.parents


åå¼è¦ç´ ã¸æ¨ªç§»å
.next_sibling / .previous_sibling
.next_siblings / .previous_siblings


åå¾ã®è¦ç´ ã¸ç§»å
.next_element / .previous_element
.next_elements / .previous_elements




ãã¼ã¹ããªã¼ãæ¤ç´¢
ãã£ã«ã¿ã¼ã®ç¨®é¡
æå­å
æ­£è¦è¡¨ç¾
ãªã¹ã
Trueå¤
é¢æ°


find_all()
nameå¼æ°
ã­ã¼ã¯ã¼ãå¼æ°
CSSã®ã¯ã©ã¹ã§æ¤ç´¢
textå¼æ°
limitå¼æ°
recursiveå¼æ°
ã·ã§ã¼ãã«ãã


find()
find_parents() / find_parent()
find_next_siblings() / find_next_sibling()
find_previous_siblings() / find_previous_sibling()
find_all_next() / find_next()
find_all_previous() / find_previous()
CSSã»ã¬ã¯ã¿


ãã¼ã¹ããªã¼ãä¿®æ­£
ååãå±æ§ã®å¤æ´
.string ã®ä¿®æ­£
append()
BeautifulSoup.new_string() / .new_tag()
insert()
insert_before() / insert_after()
clear()
extract()
decompose()
replace_with()
wrap()
unwrap()


åºå
ãããã«åºå
ä¸è¡ã«åºå
ãã©ã¼ããããæå®
get_text()


ãã¼ãµã¼ã®æå®
ãã¼ãµã¼ã®éã


ã¨ã³ã³ã¼ã
åºåã®ã¨ã³ã³ã¼ã
Unicode, Dammit
ã¹ãã¼ãå¼ç¨ç¬¦
è¤æ°ã®æå­ã³ã¼ã




ãã­ã¥ã¡ã³ãã®ä¸é¨ããã¼ã¹
SoupStrainer


ãã©ãã«ã·ã¥ã¼ãã£ã³ã°
diagnose()
ãã¼ã¹æã«åºãã¨ã©ã¼
ãã¼ã¸ã§ã³éãã®åé¡
XMLã®ãã¼ã¹
ãã®ä»ã®ãã¼ãµã¼ã®åé¡
ãã®ä»
ããã©ã¼ãã³ã¹æ¹å


Beautiful Soup 3
BS4ã¸ã®ç§»è¡
ãã¼ãµã¼
ã¡ã½ããå
ã¸ã§ãã¬ã¼ã¿ã¼
XML
ã¨ã³ãã£ãã£
ãã®ä»





This Page

Show Source


Quick search







    Enter search terms or a module, class or function name.
    








Navigation


index
Beautiful Soup 4.2.0 Doc. æ¥æ¬èªè¨³ (2013-11-19æçµæ´æ°) »



        © Copyright 2013, Leonard Richardson.
      Created using Sphinx 1.2.
    


